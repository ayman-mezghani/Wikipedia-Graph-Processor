{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import community\n",
    "\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "from neo4j import GraphDatabase, Driver\n",
    "\n",
    "import pyspark.ml\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import IDF, Tokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_graph(path):\n",
    "    print('importing graph from :', path)\n",
    "    directed_g = nx.read_gexf(path, node_type=None, relabel=True)\n",
    "    undirected_g = directed_g.to_undirected()\n",
    "    return undirected_g, directed_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_graph(g):\n",
    "    print('number of nodes : ' + str(len(g)))\n",
    "    fig, ax = plt.subplots(figsize=(70, 50)) # set size\n",
    "    nx.draw(g, with_labels=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_graph(graph):\n",
    "    print('cleaning graph')\n",
    "    #Degree computation\n",
    "    nodes_with_degrees = graph.degree\n",
    "    #mean\n",
    "    mean_deg = statistics.mean(l[1] for l in nodes_with_degrees)\n",
    "    #std\n",
    "    std_deg = statistics.stdev(l[1] for l in nodes_with_degrees)\n",
    "    #threshold\n",
    "    threshold = mean_deg + std_deg*std_deg/2 \n",
    "\n",
    "    #Filtering extremely highly connected nodes\n",
    "    nodes_to_remove = list(filter(lambda d : d[1] > threshold, nodes_with_degrees))\n",
    "    n,d = zip(*nodes_to_remove)\n",
    "    graph.remove_nodes_from(n)\n",
    "    \n",
    "    #Filtering isolated nodes\n",
    "    nodes_with_degrees = graph.degree\n",
    "    nodes_to_remove = list(filter(lambda d : d[1] == 0, nodes_with_degrees))\n",
    "    n,d = zip(*nodes_to_remove)\n",
    "    graph.remove_nodes_from(n)\n",
    "\n",
    "    print('remaining nodes : ' + str(len(graph)))\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only largest connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_connected_component(graph):\n",
    "    print('largest connected component')\n",
    "    gcc = max(nx.connected_component_subgraphs(graph), key=len)\n",
    "    print('remaining nodes : ' + str(len(gcc)))\n",
    "    return gcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning using Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communities_louvain(graph):\n",
    "    louvain_communities = community.best_partition(graph, resolution=1)\n",
    "    louvain_communities_dict = {}\n",
    "    for key, value in sorted(louvain_communities.items()):\n",
    "        louvain_communities_dict.setdefault(value, []).append(key)\n",
    "\n",
    "    print('detcted',len(louvain_communities_dict),'communities')\n",
    "    \n",
    "    return louvain_communities_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning using Leiden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/leidenalg/\n",
    "https://www.nature.com/articles/s41598-019-41695-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communities_leiden(graph):\n",
    "    #print(graph.nodes().data())\n",
    "    nx.write_graphml(graph,'graph.graphml')\n",
    "    graphi = ig.read('graph.graphml',format=\"graphml\")\n",
    "    partition = la.find_partition(graphi, la.ModularityVertexPartition);\n",
    "    print(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#communities_leiden(G_undir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categoriy of each partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of categories of a page\n",
    "def get_categories(page_name):\n",
    "    c = list()\n",
    "    with driver.session() as session:\n",
    "        with session.begin_transaction() as tx:\n",
    "            for record in tx.run(\"MATCH (p:Page)-[:BELONGS_TO]->(c:Category) \"\n",
    "                                 \"WHERE p.title = {page_name} \"\n",
    "                                 \"AND NOT exists((c)-[:BELONGS_TO]->(:Category {title: \\'Hidden_categories\\'})) \"\n",
    "                                 \"RETURN c.title\", \n",
    "                                 page_name = page_name ):\n",
    "                #print(record[\"c.title\"])\n",
    "                c.append(record[\"c.title\"])\n",
    "    return c\n",
    "\n",
    "#map each element to frequency in a list    \n",
    "def count_frequency(my_list): \n",
    "      \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    for items in my_list: \n",
    "        freq[items] = my_list.count(items)\n",
    "    return freq\n",
    "\n",
    "#iterate over pages dict partition\n",
    "def part_category_fetch(key, dic):\n",
    "    cat = []\n",
    "    for title in dic[key]:\n",
    "        cat += get_categories(title)\n",
    "    #print('done fetching')\n",
    "    return cat\n",
    "\n",
    "def fetcher(bpd):\n",
    "    part_cat = {}\n",
    "    \n",
    "    for part in sorted(bpd):\n",
    "        #print(part)\n",
    "        cat = part_category_fetch(part, bpd)\n",
    "        #print(cat)\n",
    "        part_cat.setdefault(part, cat)\n",
    "    \n",
    "    return part_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch categories for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_categories(bpd):\n",
    "    part_cat_dict = fetcher(bpd)\n",
    "    \n",
    "    return part_cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_frequencies(d):\n",
    "    part_cat_dict_freq = {}\n",
    "    for e in d:\n",
    "        cat_map_freq = count_frequency(d[e])\n",
    "        part_cat_dict_freq.setdefault(e, cat_map_freq)\n",
    "    return part_cat_dict_freq\n",
    " \n",
    "def find_max_freq(p):\n",
    "    max_part_cat = {}\n",
    "    for e in p:\n",
    "        ls = list(p[e].keys())\n",
    "        cat = ls[0]\n",
    "        for x in ls:\n",
    "            if p[e][cat] < p[e][x]:\n",
    "                cat = x\n",
    "        max_part_cat.setdefault(e, cat)\n",
    "    return max_part_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_largest_communities(c, n):\n",
    "    x = min(n, len(c))\n",
    "    print('getting', x, 'largest communities')\n",
    "    \n",
    "    l = []\n",
    "    for e in sorted(c):\n",
    "        l.append(c[e])\n",
    "    \n",
    "    tmp = sorted(l, key=len, reverse=True)[:x]\n",
    "    \n",
    "    res = {}\n",
    "    for i in range(x):\n",
    "        res.setdefault(i, tmp[i])\n",
    "    \n",
    "    length = 0\n",
    "    for e in res:\n",
    "        length += len(res[e])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_inverse_keyval(d):\n",
    "    res = {}\n",
    "    for key, value in sorted(d.items()):\n",
    "        for v in value:\n",
    "            res.setdefault(v, key)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_attribute(G, dictionary, name):\n",
    "    nx.set_node_attributes(G, dictionary, name)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ld(path, n):\n",
    "    undirected_g, directed_g = import_graph(path)\n",
    "    #verify_graph(g)\n",
    "    gg = largest_connected_component(clean_graph(undirected_g))\n",
    "    #verify_graph(gg)\n",
    "    \n",
    "    communities_dict = communities_louvain(gg)\n",
    "    \n",
    "    communities = get_n_largest_communities(communities_dict, n)\n",
    "    \n",
    "    undirected_graph_ = gg.subgraph([x for y in communities.values() for x in y])\n",
    "    directed_graph_ = directed_g.subgraph([x for y in communities.values() for x in y])\n",
    "    \n",
    "    communities_ = dic_inverse_keyval(communities)\n",
    "    \n",
    "    undirected_graph = add_attribute(undirected_graph_, communities_, \"Community\")\n",
    "    directed_graph = add_attribute(directed_graph_, communities_, \"Community\")\n",
    "        \n",
    "    print('new number of nodes is :', len(directed_graph))\n",
    "    \n",
    "    part_cat_dict = fetch_categories(communities)\n",
    "    \n",
    "    return undirected_graph, directed_graph, communities, part_cat_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "    print('tokenizing')\n",
    "    tokenizer = Tokenizer(inputCol=\"categories\", outputCol=\"raw\")\n",
    "    res = tokenizer.transform(df)\n",
    "    return res\n",
    "    \n",
    "def stop_words_remove(df):\n",
    "    print('stopWords removal')\n",
    "    remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"words\")\n",
    "    res = remover.transform(df)\n",
    "    return res\n",
    "\n",
    "def lemmatize(df):\n",
    "    print('lemmatization')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatizer_udf = udf(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens], ArrayType(StringType()))\n",
    "    res = df.withColumn(\"words\", lemmatizer_udf(\"words\"))\n",
    "    return res\n",
    "\n",
    "def stem(df):\n",
    "    print('stemming')\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "    res = df.withColumn(\"words\", stemmer_udf(\"words\"))\n",
    "    return res\n",
    "\n",
    "def cv_fit(df) :   \n",
    "    print('countVectorizer')\n",
    "    countVectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "    cvmodel = countVectorizer.fit(df)\n",
    "    return cvmodel\n",
    "\n",
    "def cv_transform(cvmodel, df):\n",
    "    res = cvmodel.transform(df)\n",
    "    return res\n",
    "\n",
    "def idf(df):\n",
    "    print('IDF')\n",
    "    idf_ = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf_.fit(df)\n",
    "    res = idfModel.transform(df)\n",
    "    return res\n",
    "    \n",
    "    #dataset = rescaledData.select('cluster','categories', 'features')\n",
    "    #print(dataset)\n",
    "\n",
    "    #dataset.show(truncate=False)\n",
    "    \n",
    "def lda_fit(df):\n",
    "    # Trains a LDA model.\n",
    "    print('training LDA')\n",
    "    lda_ = LDA(k=df.count(), maxIter=50)\n",
    "    ldaModel = lda_.fit(df)\n",
    "    return ldaModel\n",
    "\n",
    "def lda_transform(ldaModel, df):\n",
    "    print('LDA transformation')\n",
    "    transformed = ldaModel.transform(df)\n",
    "    #transformed.show()\n",
    "    return transformed\n",
    "    \n",
    "#    l = transformed.select('topicDistribution').first()[0]\n",
    "#    print(transformed.first())\n",
    "#    m = list(l).index(max(l))\n",
    "#    print('\\ntopic index is :',m)\n",
    "#    print(topics.take(m+1)[m])\n",
    "    \n",
    "def show_topic_description(ldaModel, cvmodel):\n",
    "    topicIndices = ldaModel.describeTopics(maxTermsPerTopic = 5)\n",
    "    vocabList = cvmodel.vocabulary\n",
    "    tops = []\n",
    "    for i,t,w in topicIndices.collect():\n",
    "        print('Topic %d:' % i)\n",
    "        entry = []\n",
    "        for j in range(len(t)):\n",
    "            entry.append(vocabList[t[j]])\n",
    "            #print('\\t', vocabList[t[j]], w[j])\n",
    "        print(entry)\n",
    "        tops.append(entry)\n",
    "        \n",
    "    return tops\n",
    "    \n",
    "def get_topics(communities, tops, transformed):\n",
    "    cluster_topicDist = sorted(transformed.select('cluster', 'topicDistribution').collect())\n",
    "    cluster_topicTerms = []\n",
    "    for e in cluster_topicDist:\n",
    "        m = list(e[1]).index(max(e[1]))\n",
    "        cluster_topicTerms.append(tops[m])\n",
    "\n",
    "    df2_ = []\n",
    "    for k in sorted(communities.keys()):\n",
    "        df2_.append((k, ' - '.join(communities[k]), ' - '.join(cluster_topicTerms[k])))\n",
    "    \n",
    "    partitionsData2 = spark.createDataFrame(df2_, ['cluster', 'page names', 'LDA topics'])\n",
    "    partitionsData2.select('cluster', 'LDA topics').show(truncate=False)\n",
    "    return partitionsData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def topics_with_ml(communities, part_cat_dict):\n",
    "    df_ = []\n",
    "    for p in part_cat_dict:\n",
    "        df_.append((p, ' '.join(part_cat_dict[p]).replace('_', ' ').replace(',', '')\\\n",
    "                    .replace('\\\\\\'', ' ').replace('(', '').replace(')', '').lower()))\n",
    "\n",
    "    partitionsData = spark.createDataFrame(df_, ['cluster', 'categories'])\n",
    "\n",
    "    tokenized = tokenize(partitionsData)\n",
    "    cleaned = stop_words_remove(tokenized)\n",
    "    lemmatized = lemmatize(cleaned)\n",
    "    #stemmed = stem(lemmatized)\n",
    "    #cvModel = cv_fit(stemmed)\n",
    "    cvModel = cv_fit(lemmatized)\n",
    "    #cv = cv_transform(cvModel, stemmed)\n",
    "    cv = cv_transform(cvModel, lemmatized)\n",
    "    rescaled = idf(cv)\n",
    "    ldaModel = lda_fit(rescaled)\n",
    "    ldaTransformed = lda_transform(ldaModel, rescaled)\n",
    "    tops = show_topic_description(ldaModel, cvModel)\n",
    "    final = get_topics(communities, tops, ldaTransformed)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness_centrality_nodes(graph, clusters_dict):\n",
    "    res = {}\n",
    "    for e in clusters_dict:\n",
    "        H = graph.subgraph(clusters_dict[e])\n",
    "        d = nx.algorithms.centrality.betweenness_centrality_subset(H, H.nodes, H.nodes)\n",
    "        \n",
    "        m = 0\n",
    "        n = None\n",
    "        for i in d:\n",
    "            if d[i] > m:\n",
    "                m = d[i]\n",
    "                n = i\n",
    "        res.setdefault(e, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pagerank(dir_graph, clusters_dict):\n",
    "    pr = nx.algorithms.link_analysis.pagerank_alg.pagerank(dir_graph)\n",
    "    res = {}\n",
    "    for i in clusters_dict:\n",
    "        m = 0\n",
    "        n = None\n",
    "        for p in clusters_dict[i]:\n",
    "            if pr[p] > m:\n",
    "                m = pr[p]\n",
    "                n = p\n",
    "        res.setdefault(i, n)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pagerank_on_clusters(dir_graph, clusters_dict):\n",
    "    res = {}\n",
    "    for e in clusters_dict:\n",
    "        H = dir_graph.subgraph(clusters_dict[e])\n",
    "        pr = nx.algorithms.link_analysis.pagerank_alg.pagerank(H)\n",
    "        m = 0\n",
    "        n = None\n",
    "        for i in clusters_dict[e]:\n",
    "            if pr[i] > m:\n",
    "                m = pr[i]\n",
    "                n = i\n",
    "        res.setdefault(e, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_degree(graph, clusters_dict):\n",
    "    d = graph.degree\n",
    "    res = {}\n",
    "    for i in clusters_dict:\n",
    "        m = 0\n",
    "        n = None\n",
    "        for p in clusters_dict[i]:\n",
    "            if d[p] > m:\n",
    "                m = d[p]\n",
    "                n = p\n",
    "        res.setdefault(i, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_degree_on_clusters(graph, clusters_dict):\n",
    "    res = {}\n",
    "    for e in clusters_dict:\n",
    "        H = graph.subgraph(clusters_dict[e])\n",
    "        d = H.degree\n",
    "        m = 0\n",
    "        n = None\n",
    "        for p in clusters_dict[e]:\n",
    "            if d[p] > m:\n",
    "                m = d[p]\n",
    "                n = p\n",
    "        res.setdefault(e, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df, m, c, pr, pr2, d, d2):\n",
    "    def get_maxx(i):\n",
    "        return m[i]\n",
    "    udf_get_maxx = udf(get_maxx, StringType())\n",
    "\n",
    "    def get_central(i):\n",
    "        return c[i]\n",
    "    udf_get_central = udf(get_central, StringType())\n",
    "    \n",
    "    def get_pr(i):\n",
    "        return pr[i]\n",
    "    udf_get_pr = udf(get_pr, StringType())\n",
    "    \n",
    "    def get_pr2(i):\n",
    "        return pr2[i]\n",
    "    udf_get_pr2 = udf(get_pr2, StringType())\n",
    "    \n",
    "    def get_d(i):\n",
    "        return d[i]\n",
    "    udf_get_d = udf(get_d, StringType())\n",
    "    \n",
    "    def get_d2(i):\n",
    "        return d2[i]\n",
    "    udf_get_d2 = udf(get_d2, StringType())\n",
    "\n",
    "    a = df.withColumn('betweenness central node', udf_get_central('cluster'))\\\n",
    "    .withColumn('max pagerank', udf_get_pr('cluster'))\\\n",
    "    .withColumn('max isolated pagerank', udf_get_pr2('cluster'))\\\n",
    "    .withColumn('max degree', udf_get_d('cluster'))\\\n",
    "    .withColumn('max isolated degree', udf_get_d2('cluster'))\\\n",
    "    .withColumn('max category', udf_get_maxx('cluster'))\n",
    "    \n",
    "    #a.show()\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ayman/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark warehouse set to : /home/ayman/warehouse\n",
      "importing graph from : graphs/peaks_graph_20190901_20190915.gexf\n",
      "cleaning graph\n",
      "remaining nodes : 1009\n",
      "largest connected component\n",
      "remaining nodes : 776\n",
      "detcted 38 communities\n",
      "getting 20 largest communities\n",
      "new number of nodes is : 662\n",
      "check equality 662\n",
      "tokenizing\n",
      "stopWords removal\n",
      "lemmatization\n",
      "countVectorizer\n",
      "IDF\n",
      "training LDA\n",
      "LDA transformation\n",
      "Topic 0:\n",
      "['footballer', 'player', 'manager', 'cf', 'football']\n",
      "Topic 1:\n",
      "['actress', 'film', 'canadian', 'television', 'actor']\n",
      "Topic 2:\n",
      "['11', 'attack', '2001', 'september', 'terrorism']\n",
      "Topic 3:\n",
      "['kochi', 'religiously', 'height', 'competition', '1819']\n",
      "Topic 4:\n",
      "['k.r.c.', 'lacrosse', 'language', 'somerset', 'clerk']\n",
      "Topic 5:\n",
      "['space', 'moon', 'indian', 'astronaut', 'engineer']\n",
      "Topic 6:\n",
      "['russia', 'carolina', 'rapper', 'dáil', 'meps']\n",
      "Topic 7:\n",
      "['mp', 'uk', 'constituency', '2015–2017', 'kingdom']\n",
      "Topic 8:\n",
      "['formula', 'driver', 'racing', 'fia', 'f4']\n",
      "Topic 9:\n",
      "['11', 'attack', 'arabian', 'murderer', 'saudi']\n",
      "Topic 10:\n",
      "['mp', 'uk', 'constituency', 'kingdom', '2017–']\n",
      "Topic 11:\n",
      "['anti-communism', 'rattigan', 'region', 'laureate', 'montenegro']\n",
      "Topic 12:\n",
      "['tennis', 'serbian', 'olympics', 'volleyball', 'champion']\n",
      "Topic 13:\n",
      "['winter', 'tonga', 'alpine', 'skier', 'space']\n",
      "Topic 14:\n",
      "['album', 'daniel', 'johnston', 'character', 'fictional']\n",
      "Topic 15:\n",
      "['treaty', '1912', 'rebellion', '1780s', '1905']\n",
      "Topic 16:\n",
      "['texas', 'missouri', 'orbán', 'gabon', 'society']\n",
      "Topic 17:\n",
      "['spy', 'iran', 'entertainer', '1944', 'format']\n",
      "Topic 18:\n",
      "['driver', 'formula', '11', 'attack', 'fia']\n",
      "Topic 19:\n",
      "['officer', 'baptist', 'aske', 'billionaire', 'hurd']\n",
      "+-------+---------------------------------------------------+\n",
      "|cluster|LDA topics                                         |\n",
      "+-------+---------------------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–           |\n",
      "|1      |11 - attack - arabian - murderer - saudi           |\n",
      "|2      |winter - tonga - alpine - skier - space            |\n",
      "|3      |russia - carolina - rapper - dáil - meps           |\n",
      "|4      |winter - tonga - alpine - skier - space            |\n",
      "|5      |actress - film - canadian - television - actor     |\n",
      "|6      |treaty - 1912 - rebellion - 1780s - 1905           |\n",
      "|7      |footballer - player - manager - cf - football      |\n",
      "|8      |footballer - player - manager - cf - football      |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–           |\n",
      "|10     |space - moon - indian - astronaut - engineer       |\n",
      "|11     |album - daniel - johnston - character - fictional  |\n",
      "|12     |11 - attack - arabian - murderer - saudi           |\n",
      "|13     |footballer - player - manager - cf - football      |\n",
      "|14     |tennis - serbian - olympics - volleyball - champion|\n",
      "|15     |russia - carolina - rapper - dáil - meps           |\n",
      "|16     |actress - film - canadian - television - actor     |\n",
      "|17     |album - daniel - johnston - character - fictional  |\n",
      "|18     |driver - formula - 11 - attack - fia               |\n",
      "|19     |actress - film - canadian - television - actor     |\n",
      "+-------+---------------------------------------------------+\n",
      "\n",
      "betweenness central nodes visualization\n",
      "+-------+---------------------------------------------------+-----------------------------------------------------+\n",
      "|cluster|LDA topics                                         |betweenness central node                             |\n",
      "+-------+---------------------------------------------------+-----------------------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–           |Justine_Greening                                     |\n",
      "|1      |11 - attack - arabian - murderer - saudi           |United_Airlines_Flight_175                           |\n",
      "|2      |winter - tonga - alpine - skier - space            |September_6                                          |\n",
      "|3      |russia - carolina - rapper - dáil - meps           |Sarah_Palin                                          |\n",
      "|4      |winter - tonga - alpine - skier - space            |2019                                                 |\n",
      "|5      |actress - film - canadian - television - actor     |Film                                                 |\n",
      "|6      |treaty - 1912 - rebellion - 1780s - 1905           |Zimbabwe                                             |\n",
      "|7      |footballer - player - manager - cf - football      |September_3                                          |\n",
      "|8      |footballer - player - manager - cf - football      |La_Liga                                              |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–           |2019_Speaker_of_the_British_House_of_Commons_election|\n",
      "|10     |space - moon - indian - astronaut - engineer       |Indian_Space_Research_Organisation                   |\n",
      "|11     |album - daniel - johnston - character - fictional  |Daniel_Johnston                                      |\n",
      "|12     |11 - attack - arabian - murderer - saudi           |Khalid_al-Mihdhar                                    |\n",
      "|13     |footballer - player - manager - cf - football      |September_10                                         |\n",
      "|14     |tennis - serbian - olympics - volleyball - champion|Shanghai_Masters_(tennis)                            |\n",
      "|15     |russia - carolina - rapper - dáil - meps           |Juncker_Commission                                   |\n",
      "|16     |actress - film - canadian - television - actor     |Demi_Moore                                           |\n",
      "|17     |album - daniel - johnston - character - fictional  |Simpson_family                                       |\n",
      "|18     |driver - formula - 11 - attack - fia               |Giuliano_Alesi                                       |\n",
      "|19     |actress - film - canadian - television - actor     |Joan_Rivers                                          |\n",
      "+-------+---------------------------------------------------+-----------------------------------------------------+\n",
      "\n",
      "max pagerank visualization\n",
      "+-------+---------------------------------------------------+--------------------------------------------------------+\n",
      "|cluster|LDA topics                                         |max pagerank                                            |\n",
      "+-------+---------------------------------------------------+--------------------------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–           |Jane_Dodds                                              |\n",
      "|1      |11 - attack - arabian - murderer - saudi           |Artwork_damaged_or_destroyed_in_the_September_11_attacks|\n",
      "|2      |winter - tonga - alpine - skier - space            |1950_United_States_Senate_election_in_California        |\n",
      "|3      |russia - carolina - rapper - dáil - meps           |Azealia_Banks                                           |\n",
      "|4      |winter - tonga - alpine - skier - space            |Sinking_of_MV_Conception                                |\n",
      "|5      |actress - film - canadian - television - actor     |List_of_international_goals_scored_by_Lionel_Messi      |\n",
      "|6      |treaty - 1912 - rebellion - 1780s - 1905           |Canaan_Banana                                           |\n",
      "|7      |footballer - player - manager - cf - football      |Victoria_Cross                                          |\n",
      "|8      |footballer - player - manager - cf - football      |Todd_Cantwell                                           |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–           |2019_Speaker_of_the_British_House_of_Commons_election   |\n",
      "|10     |space - moon - indian - astronaut - engineer       |Beresheet                                               |\n",
      "|11     |album - daniel - johnston - character - fictional  |Hi,_How_Are_You_Daniel_Johnston?                        |\n",
      "|12     |11 - attack - arabian - murderer - saudi           |Hamza_al-Ghamdi                                         |\n",
      "|13     |footballer - player - manager - cf - football      |Battle_of_Baltimore                                     |\n",
      "|14     |tennis - serbian - olympics - volleyball - champion|2019_Moselle_Open_–_Singles                             |\n",
      "|15     |russia - carolina - rapper - dáil - meps           |2019_Russian_elections                                  |\n",
      "|16     |actress - film - canadian - television - actor     |John_Alexander_(artist)                                 |\n",
      "|17     |album - daniel - johnston - character - fictional  |The_Simpsons_(season_9)                                 |\n",
      "|18     |driver - formula - 11 - attack - fia               |2019_Spa-Francorchamps_FIA_Formula_2_round              |\n",
      "|19     |actress - film - canadian - television - actor     |Michele_Lee                                             |\n",
      "+-------+---------------------------------------------------+--------------------------------------------------------+\n",
      "\n",
      "max pagerank2 visualization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------------------------------+--------------------------------------------------------+\n",
      "|cluster|LDA topics                                         |max isolated pagerank                                   |\n",
      "+-------+---------------------------------------------------+--------------------------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–           |Jane_Dodds                                              |\n",
      "|1      |11 - attack - arabian - murderer - saudi           |Artwork_damaged_or_destroyed_in_the_September_11_attacks|\n",
      "|2      |winter - tonga - alpine - skier - space            |1950_United_States_Senate_election_in_California        |\n",
      "|3      |russia - carolina - rapper - dáil - meps           |2012_Benghazi_attack                                    |\n",
      "|4      |winter - tonga - alpine - skier - space            |Sinking_of_MV_Conception                                |\n",
      "|5      |actress - film - canadian - television - actor     |List_of_international_goals_scored_by_Lionel_Messi      |\n",
      "|6      |treaty - 1912 - rebellion - 1780s - 1905           |Canaan_Banana                                           |\n",
      "|7      |footballer - player - manager - cf - football      |Victoria_Cross                                          |\n",
      "|8      |footballer - player - manager - cf - football      |Todd_Cantwell                                           |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–           |2019_Speaker_of_the_British_House_of_Commons_election   |\n",
      "|10     |space - moon - indian - astronaut - engineer       |Beresheet                                               |\n",
      "|11     |album - daniel - johnston - character - fictional  |Hi,_How_Are_You_Daniel_Johnston?                        |\n",
      "|12     |11 - attack - arabian - murderer - saudi           |Hamza_al-Ghamdi                                         |\n",
      "|13     |footballer - player - manager - cf - football      |Battle_of_Baltimore                                     |\n",
      "|14     |tennis - serbian - olympics - volleyball - champion|2019_Moselle_Open_–_Singles                             |\n",
      "|15     |russia - carolina - rapper - dáil - meps           |2019_Russian_elections                                  |\n",
      "|16     |actress - film - canadian - television - actor     |John_Alexander_(artist)                                 |\n",
      "|17     |album - daniel - johnston - character - fictional  |The_Simpsons_(season_9)                                 |\n",
      "|18     |driver - formula - 11 - attack - fia               |2019_Spa-Francorchamps_FIA_Formula_2_round              |\n",
      "|19     |actress - film - canadian - television - actor     |Michele_Lee                                             |\n",
      "+-------+---------------------------------------------------+--------------------------------------------------------+\n",
      "\n",
      "max deg visualization\n",
      "+-------+---------------------------------------------------+--------------------------------------+\n",
      "|cluster|LDA topics                                         |max degree                            |\n",
      "+-------+---------------------------------------------------+--------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–           |Dominic_Grieve                        |\n",
      "|1      |11 - attack - arabian - murderer - saudi           |United_Airlines_Flight_175            |\n",
      "|2      |winter - tonga - alpine - skier - space            |September_6                           |\n",
      "|3      |russia - carolina - rapper - dáil - meps           |John_Bolton                           |\n",
      "|4      |winter - tonga - alpine - skier - space            |2019                                  |\n",
      "|5      |actress - film - canadian - television - actor     |Film                                  |\n",
      "|6      |treaty - 1912 - rebellion - 1780s - 1905           |Zimbabwe                              |\n",
      "|7      |footballer - player - manager - cf - football      |September_3                           |\n",
      "|8      |footballer - player - manager - cf - football      |La_Liga                               |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–           |Chairman_of_Ways_and_Means            |\n",
      "|10     |space - moon - indian - astronaut - engineer       |Indian_Space_Research_Organisation    |\n",
      "|11     |album - daniel - johnston - character - fictional  |Daniel_Johnston                       |\n",
      "|12     |11 - attack - arabian - murderer - saudi           |Ziad_Jarrah                           |\n",
      "|13     |footballer - player - manager - cf - football      |September_10                          |\n",
      "|14     |tennis - serbian - olympics - volleyball - champion|Novak_Djokovic                        |\n",
      "|15     |russia - carolina - rapper - dáil - meps           |Conte_II_Cabinet                      |\n",
      "|16     |actress - film - canadian - television - actor     |Burt_Bacharach                        |\n",
      "|17     |album - daniel - johnston - character - fictional  |The_City_of_New_York_vs._Homer_Simpson|\n",
      "|18     |driver - formula - 11 - attack - fia               |Giuliano_Alesi                        |\n",
      "|19     |actress - film - canadian - television - actor     |Joan_Rivers                           |\n",
      "+-------+---------------------------------------------------+--------------------------------------+\n",
      "\n",
      "max deg2 visualization\n",
      "+-------+---------------------------------------------------+--------------------------------------+\n",
      "|cluster|LDA topics                                         |max isolated degree                   |\n",
      "+-------+---------------------------------------------------+--------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–           |Nicholas_Soames                       |\n",
      "|1      |11 - attack - arabian - murderer - saudi           |Collapse_of_the_World_Trade_Center    |\n",
      "|2      |winter - tonga - alpine - skier - space            |September_6                           |\n",
      "|3      |russia - carolina - rapper - dáil - meps           |John_Bolton                           |\n",
      "|4      |winter - tonga - alpine - skier - space            |2019                                  |\n",
      "|5      |actress - film - canadian - television - actor     |Film                                  |\n",
      "|6      |treaty - 1912 - rebellion - 1780s - 1905           |Zimbabwe                              |\n",
      "|7      |footballer - player - manager - cf - football      |September_3                           |\n",
      "|8      |footballer - player - manager - cf - football      |La_Liga                               |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–           |Chairman_of_Ways_and_Means            |\n",
      "|10     |space - moon - indian - astronaut - engineer       |Indian_Space_Research_Organisation    |\n",
      "|11     |album - daniel - johnston - character - fictional  |Daniel_Johnston                       |\n",
      "|12     |11 - attack - arabian - murderer - saudi           |Ahmed_al-Haznawi                      |\n",
      "|13     |footballer - player - manager - cf - football      |September_10                          |\n",
      "|14     |tennis - serbian - olympics - volleyball - champion|Novak_Djokovic                        |\n",
      "|15     |russia - carolina - rapper - dáil - meps           |Conte_II_Cabinet                      |\n",
      "|16     |actress - film - canadian - television - actor     |Crystal_Head_Vodka                    |\n",
      "|17     |album - daniel - johnston - character - fictional  |The_City_of_New_York_vs._Homer_Simpson|\n",
      "|18     |driver - formula - 11 - attack - fia               |Giuliano_Alesi                        |\n",
      "|19     |actress - film - canadian - television - actor     |Joan_Rivers                           |\n",
      "+-------+---------------------------------------------------+--------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ.setdefault('JAVA_HOME', '/usr/lib/jvm/java-1.8.0-openjdk-amd64')\n",
    "user = os.environ.get('USER')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from os import walk\n",
    "\n",
    "mypath = 'graphs/'\n",
    "max_num_communities = 20\n",
    "output_path = 'output/'\n",
    "#(_, _, filenames) = next(walk(mypath))\n",
    "filenames = [\"peaks_graph_20190901_20190915.gexf\"]\n",
    "\n",
    "global driver\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=('neo4j', 'tototo'))\n",
    "\n",
    "global spark\n",
    "spark = SparkSession.builder.appName('graph processing').config(\"spark.master\", \"local[*]\").config(\"spark.sql.warehouse.dir\", \"/home/\"+user+\"/warehouse\").getOrCreate()\n",
    "print(\"Spark warehouse set to :\", spark.conf.get('spark.sql.warehouse.dir'))\n",
    "\n",
    "for f in sorted(filenames):\n",
    "    path = mypath + f\n",
    "    (G_undir, G_dir, communities, part_cat_dict) = ld(path, max_num_communities)\n",
    "        \n",
    "    maxx = find_max_freq(count_all_frequencies(part_cat_dict))\n",
    "    \n",
    "    lda_df = topics_with_ml(communities, part_cat_dict)\n",
    "    \n",
    "    betweenness_central_nodes = betweenness_centrality_nodes(G_undir, communities)\n",
    "    \n",
    "    pr_result = max_pagerank(G_dir, communities)\n",
    "    pr2_result = max_pagerank_on_clusters(G_dir, communities)\n",
    "    \n",
    "    deg = max_degree(G_undir, communities)\n",
    "    deg2 = max_degree_on_clusters(G_undir, communities)\n",
    "    \n",
    "    res = merge(lda_df, maxx, betweenness_central_nodes, pr_result, pr2_result, deg, deg2)\n",
    "    \n",
    "    print('betweenness central nodes visualization')\n",
    "    res.select('cluster', 'LDA topics', 'betweenness central node').show(truncate=False)\n",
    "    print('max pagerank visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max pagerank').show(truncate=False)\n",
    "    print('max pagerank2 visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max isolated pagerank').show(truncate=False)\n",
    "    print('max deg visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max degree').show(truncate=False)\n",
    "    print('max deg2 visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max isolated degree').show(truncate=False)\n",
    "    \n",
    "    name = f[12:-5]\n",
    "    path = output_path+name+\"/\"\n",
    "    res.coalesce(1).write.csv(path, mode = 'overwrite')\n",
    "    nx.write_gexf(G_undir, path+name+\".gexf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insider_neighbors_ratio(G, communities, ls):\n",
    "    res = {}\n",
    "    for cluster in ls:\n",
    "        node = ls[cluster]\n",
    "        neighbors = list(nx.classes.function.neighbors(G, node))\n",
    "        community_nodes = communities[cluster]\n",
    "        count = 0\n",
    "    \n",
    "        for n in neighbors:\n",
    "            if n in community_nodes:\n",
    "                count-=-1 #why not ;p\n",
    "    \n",
    "        ratio = \"{0:.2f}\".format(100 * count / len(neighbors))+'%'\n",
    "    \n",
    "        print(cluster, node, ratio)\n",
    "    \n",
    "        res.setdefault(cluster, (node, ratio))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Dominic_Grieve 88.89%\n",
      "1 United_Airlines_Flight_175 72.41%\n",
      "2 September_6 80.95%\n",
      "3 John_Bolton 100.00%\n",
      "4 2019 72.73%\n",
      "5 Film 92.31%\n",
      "6 Zimbabwe 82.05%\n",
      "7 September_3 87.50%\n",
      "8 La_Liga 100.00%\n",
      "9 Chairman_of_Ways_and_Means 88.89%\n",
      "10 Indian_Space_Research_Organisation 100.00%\n",
      "11 Daniel_Johnston 96.00%\n",
      "12 Ziad_Jarrah 67.86%\n",
      "13 September_10 83.33%\n",
      "14 Novak_Djokovic 90.91%\n",
      "15 Conte_II_Cabinet 83.33%\n",
      "16 Burt_Bacharach 75.00%\n",
      "17 The_City_of_New_York_vs._Homer_Simpson 85.71%\n",
      "18 Giuliano_Alesi 91.67%\n",
      "19 Joan_Rivers 100.00%\n"
     ]
    }
   ],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Nicholas_Soames 100.00%\n",
      "1 Collapse_of_the_World_Trade_Center 95.56%\n",
      "2 September_6 80.95%\n",
      "3 John_Bolton 100.00%\n",
      "4 2019 72.73%\n",
      "5 Film 92.31%\n",
      "6 Zimbabwe 82.05%\n",
      "7 September_3 87.50%\n",
      "8 La_Liga 100.00%\n",
      "9 Chairman_of_Ways_and_Means 88.89%\n",
      "10 Indian_Space_Research_Organisation 100.00%\n",
      "11 Daniel_Johnston 96.00%\n",
      "12 Ahmed_al-Haznawi 73.08%\n",
      "13 September_10 83.33%\n",
      "14 Novak_Djokovic 90.91%\n",
      "15 Conte_II_Cabinet 83.33%\n",
      "16 Crystal_Head_Vodka 100.00%\n",
      "17 The_City_of_New_York_vs._Homer_Simpson 85.71%\n",
      "18 Giuliano_Alesi 91.67%\n",
      "19 Joan_Rivers 100.00%\n"
     ]
    }
   ],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, deg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Jane_Dodds 100.00%\n",
      "1 Artwork_damaged_or_destroyed_in_the_September_11_attacks 100.00%\n",
      "2 1950_United_States_Senate_election_in_California 100.00%\n",
      "3 Azealia_Banks 66.67%\n",
      "4 Sinking_of_MV_Conception 100.00%\n",
      "5 List_of_international_goals_scored_by_Lionel_Messi 100.00%\n",
      "6 Canaan_Banana 100.00%\n",
      "7 Victoria_Cross 100.00%\n",
      "8 Todd_Cantwell 100.00%\n",
      "9 2019_Speaker_of_the_British_House_of_Commons_election 100.00%\n",
      "10 Beresheet 100.00%\n",
      "11 Hi,_How_Are_You_Daniel_Johnston? 100.00%\n",
      "12 Hamza_al-Ghamdi 77.78%\n",
      "13 Battle_of_Baltimore 100.00%\n",
      "14 2019_Moselle_Open_–_Singles 100.00%\n",
      "15 2019_Russian_elections 100.00%\n",
      "16 John_Alexander_(artist) 100.00%\n",
      "17 The_Simpsons_(season_9) 100.00%\n",
      "18 2019_Spa-Francorchamps_FIA_Formula_2_round 100.00%\n",
      "19 Michele_Lee 100.00%\n"
     ]
    }
   ],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, pr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Jane_Dodds 100.00%\n",
      "1 Artwork_damaged_or_destroyed_in_the_September_11_attacks 100.00%\n",
      "2 1950_United_States_Senate_election_in_California 100.00%\n",
      "3 2012_Benghazi_attack 100.00%\n",
      "4 Sinking_of_MV_Conception 100.00%\n",
      "5 List_of_international_goals_scored_by_Lionel_Messi 100.00%\n",
      "6 Canaan_Banana 100.00%\n",
      "7 Victoria_Cross 100.00%\n",
      "8 Todd_Cantwell 100.00%\n",
      "9 2019_Speaker_of_the_British_House_of_Commons_election 100.00%\n",
      "10 Beresheet 100.00%\n",
      "11 Hi,_How_Are_You_Daniel_Johnston? 100.00%\n",
      "12 Hamza_al-Ghamdi 77.78%\n",
      "13 Battle_of_Baltimore 100.00%\n",
      "14 2019_Moselle_Open_–_Singles 100.00%\n",
      "15 2019_Russian_elections 100.00%\n",
      "16 John_Alexander_(artist) 100.00%\n",
      "17 The_Simpsons_(season_9) 100.00%\n",
      "18 2019_Spa-Francorchamps_FIA_Formula_2_round 100.00%\n",
      "19 Michele_Lee 100.00%\n"
     ]
    }
   ],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, pr2_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('betweenness central nodes visualization')\\nres.select('cluster', 'LDA topics', 'betweenness central node').show(truncate=False)\\nprint('max pagerank visualization')\\nres.select('cluster', 'LDA topics', 'max pagerank').show(truncate=False)\\nprint('max pagerank2 visualization')\\nres.select('cluster', 'LDA topics', 'max isolated pagerank').show(truncate=False)\\nprint('max deg visualization')\\nres.select('cluster', 'LDA topics', 'max degree').show(truncate=False)\\nprint('max deg2 visualization')\\nres.select('cluster', 'LDA topics', 'max isolated degree').show(truncate=False)\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print('betweenness central nodes visualization')\n",
    "res.select('cluster', 'LDA topics', 'betweenness central node').show(truncate=False)\n",
    "print('max pagerank visualization')\n",
    "res.select('cluster', 'LDA topics', 'max pagerank').show(truncate=False)\n",
    "print('max pagerank2 visualization')\n",
    "res.select('cluster', 'LDA topics', 'max isolated pagerank').show(truncate=False)\n",
    "print('max deg visualization')\n",
    "res.select('cluster', 'LDA topics', 'max degree').show(truncate=False)\n",
    "print('max deg2 visualization')\n",
    "res.select('cluster', 'LDA topics', 'max isolated degree').show(truncate=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import argparse\\n\\ndef parseArguments():\\n    # Create argument parser\\n    parser = argparse.ArgumentParser()\\n\\n    # Optional arguments\\n    parser.add_argument(\"-jdk8\", \"--jdk8Path\", help=\"path to jdk8. Default : /usr/lib/jvm/java-1.8.0-openjdk-amd64\", type=str, default=\\'/usr/lib/jvm/java-1.8.0-openjdk-amd64\\')\\n    parser.add_argument(\"-n4jadr\", \"--neo4jAddress\", help=\"neo4j database address. Default : bolt://localhost:7687\", type=str, default=\\'bolt://localhost:7687\\')\\n    parser.add_argument(\"-n4jusr\", \"--neo4jUsername\", help=\"neo4j database username. Default : neo4j\", type=str, default=\\'neo4j\\')\\n    parser.add_argument(\"-n4jpwd\", \"--neo4jPassword\", help=\"neo4j database password. Default : neo4j\", type=str, default=\\'neo4j\\')\\n    parser.add_argument(\"-ip\", \"--inputPath\", help=\"path of the directory containing the graphs. Default : graphs/\", type=str, default=\\'graphs/\\')\\n    parser.add_argument(\"-n\", \"--nOfClusters\", help=\"max number of clusters to extract. Default : 20\", type=int, default=20)\\n    parser.add_argument(\"-op\", \"--outputPath\", help=\"path of the output directory. Default : output/\", type=str, default=\\'output/\\')\\n\\n    # Parse arguments\\n    args = parser.parse_args()\\n\\n    return args\\n    \\nmain(parseArguments())\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import argparse\n",
    "\n",
    "def parseArguments():\n",
    "    # Create argument parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Optional arguments\n",
    "    parser.add_argument(\"-jdk8\", \"--jdk8Path\", help=\"path to jdk8. Default : /usr/lib/jvm/java-1.8.0-openjdk-amd64\", type=str, default='/usr/lib/jvm/java-1.8.0-openjdk-amd64')\n",
    "    parser.add_argument(\"-n4jadr\", \"--neo4jAddress\", help=\"neo4j database address. Default : bolt://localhost:7687\", type=str, default='bolt://localhost:7687')\n",
    "    parser.add_argument(\"-n4jusr\", \"--neo4jUsername\", help=\"neo4j database username. Default : neo4j\", type=str, default='neo4j')\n",
    "    parser.add_argument(\"-n4jpwd\", \"--neo4jPassword\", help=\"neo4j database password. Default : neo4j\", type=str, default='neo4j')\n",
    "    parser.add_argument(\"-ip\", \"--inputPath\", help=\"path of the directory containing the graphs. Default : graphs/\", type=str, default='graphs/')\n",
    "    parser.add_argument(\"-n\", \"--nOfClusters\", help=\"max number of clusters to extract. Default : 20\", type=int, default=20)\n",
    "    parser.add_argument(\"-op\", \"--outputPath\", help=\"path of the output directory. Default : output/\", type=str, default='output/')\n",
    "\n",
    "    # Parse arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "    \n",
    "main(parseArguments())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more centrality attributes: pagerank, degrees, and try to find others\n",
    "\n",
    "make code a sort of an executable tool with arguments etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take node with highest degree in each cluster and find its neighbors and seee how many are in the same cluster\n",
    "==> the second variant (using just insiders to compute deg and pagerank) has better ratios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
