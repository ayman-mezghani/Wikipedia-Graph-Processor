{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import community\n",
    "\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "from neo4j import GraphDatabase, Driver\n",
    "\n",
    "import pyspark.ml\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import IDF, Tokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_graph(path):\n",
    "    print('importing graph from :', path)\n",
    "    directed_g = nx.read_gexf(path, node_type=None, relabel=True)\n",
    "    undirected_g = directed_g.to_undirected()\n",
    "    return undirected_g, directed_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_graph(g):\n",
    "    print('number of nodes : ' + str(len(g)))\n",
    "    fig, ax = plt.subplots(figsize=(70, 50)) # set size\n",
    "    nx.draw(g, with_labels=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_graph(graph):\n",
    "    print('cleaning graph')\n",
    "    #Degree computation\n",
    "    nodes_with_degrees = graph.degree\n",
    "    #mean\n",
    "    mean_deg = statistics.mean(l[1] for l in nodes_with_degrees)\n",
    "    #std\n",
    "    std_deg = statistics.stdev(l[1] for l in nodes_with_degrees)\n",
    "    #threshold\n",
    "    threshold = mean_deg + std_deg*std_deg/2 \n",
    "\n",
    "    #Filtering extremely highly connected nodes\n",
    "    nodes_to_remove = list(filter(lambda d : d[1] > threshold, nodes_with_degrees))\n",
    "    n,d = zip(*nodes_to_remove)\n",
    "    graph.remove_nodes_from(n)\n",
    "    \n",
    "    #Filtering isolated nodes\n",
    "    nodes_with_degrees = graph.degree\n",
    "    nodes_to_remove = list(filter(lambda d : d[1] == 0, nodes_with_degrees))\n",
    "    n,d = zip(*nodes_to_remove)\n",
    "    graph.remove_nodes_from(n)\n",
    "\n",
    "    print('remaining nodes : ' + str(len(graph)))\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only largest connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_connected_component(graph):\n",
    "    print('largest connected component')\n",
    "    gcc = max(nx.connected_component_subgraphs(graph), key=len)\n",
    "    print('remaining nodes : ' + str(len(gcc)))\n",
    "    return gcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning using Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communities_louvain(graph):\n",
    "    louvain_communities = community.best_partition(graph, resolution=1)\n",
    "    louvain_communities_dict = {}\n",
    "    for key, value in sorted(louvain_communities.items()):\n",
    "        louvain_communities_dict.setdefault(value, []).append(key)\n",
    "\n",
    "    print('detcted',len(louvain_communities_dict),'communities')\n",
    "    \n",
    "    return louvain_communities_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning using Leiden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/leidenalg/\n",
    "https://www.nature.com/articles/s41598-019-41695-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communities_leiden(graph):\n",
    "    #print(graph.nodes().data())\n",
    "    nx.write_graphml(graph,'graph.graphml')\n",
    "    graphi = ig.read('graph.graphml',format=\"graphml\")\n",
    "    partition = la.find_partition(graphi, la.ModularityVertexPartition);\n",
    "    print(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#communities_leiden(G_undir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categoriy of each partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of categories of a page\n",
    "def get_categories(page_name):\n",
    "    c = list()\n",
    "    with driver.session() as session:\n",
    "        with session.begin_transaction() as tx:\n",
    "            for record in tx.run(\"MATCH (p:Page)-[:BELONGS_TO]->(c:Category) \"\n",
    "                                 \"WHERE p.title = {page_name} \"\n",
    "                                 \"AND NOT exists((c)-[:BELONGS_TO]->(:Category {title: \\'Hidden_categories\\'})) \"\n",
    "                                 \"RETURN c.title\", \n",
    "                                 page_name = page_name ):\n",
    "                #print(record[\"c.title\"])\n",
    "                c.append(record[\"c.title\"])\n",
    "    return c\n",
    "\n",
    "#map each element to frequency in a list    \n",
    "def count_frequency(my_list): \n",
    "      \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    for items in my_list: \n",
    "        freq[items] = my_list.count(items)\n",
    "    return freq\n",
    "\n",
    "#iterate over pages dict partition\n",
    "def part_category_fetch(key, dic):\n",
    "    cat = []\n",
    "    for title in dic[key]:\n",
    "        cat += get_categories(title)\n",
    "    #print('done fetching')\n",
    "    return cat\n",
    "\n",
    "def fetcher(bpd):\n",
    "    part_cat = {}\n",
    "    \n",
    "    for part in sorted(bpd):\n",
    "        #print(part)\n",
    "        cat = part_category_fetch(part, bpd)\n",
    "        #print(cat)\n",
    "        part_cat.setdefault(part, cat)\n",
    "    \n",
    "    return part_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch categories for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_categories(bpd):\n",
    "    part_cat_dict = fetcher(bpd)\n",
    "    \n",
    "    return part_cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_frequencies(d):\n",
    "    part_cat_dict_freq = {}\n",
    "    for e in d:\n",
    "        cat_map_freq = count_frequency(d[e])\n",
    "        part_cat_dict_freq.setdefault(e, cat_map_freq)\n",
    "    return part_cat_dict_freq\n",
    " \n",
    "def find_max_freq(p):\n",
    "    max_part_cat = {}\n",
    "    for e in p:\n",
    "        ls = list(p[e].keys())\n",
    "        cat = ls[0]\n",
    "        for x in ls:\n",
    "            if p[e][cat] < p[e][x]:\n",
    "                cat = x\n",
    "        max_part_cat.setdefault(e, cat)\n",
    "    return max_part_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_largest_communities(c, n):\n",
    "    x = min(n, len(c))\n",
    "    print('getting', x, 'largest communities')\n",
    "    \n",
    "    l = []\n",
    "    for e in sorted(c):\n",
    "        l.append(c[e])\n",
    "    \n",
    "    tmp = sorted(l, key=len, reverse=True)[:x]\n",
    "    \n",
    "    res = {}\n",
    "    for i in range(x):\n",
    "        res.setdefault(i, tmp[i])\n",
    "    \n",
    "    length = 0\n",
    "    for e in res:\n",
    "        length += len(res[e])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_inverse_keyval(d):\n",
    "    res = {}\n",
    "    for key, value in sorted(d.items()):\n",
    "        for v in value:\n",
    "            res.setdefault(v, key)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_attribute(G, dictionary, name):\n",
    "    nx.set_node_attributes(G, dictionary, name)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ld(path, n):\n",
    "    undirected_g, directed_g = import_graph(path)\n",
    "    #verify_graph(g)\n",
    "    gg = largest_connected_component(clean_graph(undirected_g))\n",
    "    #verify_graph(gg)\n",
    "    \n",
    "    communities_dict = communities_louvain(gg)\n",
    "    \n",
    "    communities = get_n_largest_communities(communities_dict, n)\n",
    "    \n",
    "    undirected_graph_ = gg.subgraph([x for y in communities.values() for x in y])\n",
    "    directed_graph_ = directed_g.subgraph([x for y in communities.values() for x in y])\n",
    "    \n",
    "    communities_ = dic_inverse_keyval(communities)\n",
    "    \n",
    "    undirected_graph = add_attribute(undirected_graph_, communities_, \"Community\")\n",
    "    directed_graph = add_attribute(directed_graph_, communities_, \"Community\")\n",
    "        \n",
    "    print('new number of nodes is :', len(directed_graph))\n",
    "    \n",
    "    part_cat_dict = fetch_categories(communities)\n",
    "    \n",
    "    return undirected_graph, directed_graph, communities, part_cat_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "    print('tokenizing')\n",
    "    tokenizer = Tokenizer(inputCol=\"categories\", outputCol=\"raw\")\n",
    "    res = tokenizer.transform(df)\n",
    "    return res\n",
    "    \n",
    "def stop_words_remove(df):\n",
    "    print('stopWords removal')\n",
    "    remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"words\")\n",
    "    res = remover.transform(df)\n",
    "    return res\n",
    "\n",
    "def lemmatize(df):\n",
    "    print('lemmatization')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatizer_udf = udf(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens], ArrayType(StringType()))\n",
    "    res = df.withColumn(\"words\", lemmatizer_udf(\"words\"))\n",
    "    return res\n",
    "\n",
    "def stem(df):\n",
    "    print('stemming')\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "    res = df.withColumn(\"words\", stemmer_udf(\"words\"))\n",
    "    return res\n",
    "\n",
    "def cv_fit(df) :   \n",
    "    print('countVectorizer')\n",
    "    countVectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "    cvmodel = countVectorizer.fit(df)\n",
    "    return cvmodel\n",
    "\n",
    "def cv_transform(cvmodel, df):\n",
    "    res = cvmodel.transform(df)\n",
    "    return res\n",
    "\n",
    "def idf(df):\n",
    "    print('IDF')\n",
    "    idf_ = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf_.fit(df)\n",
    "    res = idfModel.transform(df)\n",
    "    return res\n",
    "    \n",
    "    #dataset = rescaledData.select('cluster','categories', 'features')\n",
    "    #print(dataset)\n",
    "\n",
    "    #dataset.show(truncate=False)\n",
    "    \n",
    "def lda_fit(df):\n",
    "    # Trains a LDA model.\n",
    "    print('training LDA')\n",
    "    lda_ = LDA(k=df.count(), maxIter=50)\n",
    "    ldaModel = lda_.fit(df)\n",
    "    return ldaModel\n",
    "\n",
    "def lda_transform(ldaModel, df):\n",
    "    print('LDA transformation')\n",
    "    transformed = ldaModel.transform(df)\n",
    "    #transformed.show()\n",
    "    return transformed\n",
    "    \n",
    "#    l = transformed.select('topicDistribution').first()[0]\n",
    "#    print(transformed.first())\n",
    "#    m = list(l).index(max(l))\n",
    "#    print('\\ntopic index is :',m)\n",
    "#    print(topics.take(m+1)[m])\n",
    "    \n",
    "def show_topic_description(ldaModel, cvmodel):\n",
    "    topicIndices = ldaModel.describeTopics(maxTermsPerTopic = 5)\n",
    "    vocabList = cvmodel.vocabulary\n",
    "    tops = []\n",
    "    for i,t,w in topicIndices.collect():\n",
    "        print('Topic %d:' % i)\n",
    "        entry = []\n",
    "        for j in range(len(t)):\n",
    "            entry.append(vocabList[t[j]])\n",
    "            #print('\\t', vocabList[t[j]], w[j])\n",
    "        print(entry)\n",
    "        tops.append(entry)\n",
    "        \n",
    "    return tops\n",
    "    \n",
    "def get_topics(communities, tops, transformed):\n",
    "    cluster_topicDist = sorted(transformed.select('cluster', 'topicDistribution').collect())\n",
    "    cluster_topicTerms = []\n",
    "    for e in cluster_topicDist:\n",
    "        m = list(e[1]).index(max(e[1]))\n",
    "        cluster_topicTerms.append(tops[m])\n",
    "\n",
    "    df2_ = []\n",
    "    for k in sorted(communities.keys()):\n",
    "        df2_.append((k, ' - '.join(communities[k]), ' - '.join(cluster_topicTerms[k])))\n",
    "    \n",
    "    partitionsData2 = spark.createDataFrame(df2_, ['cluster', 'page names', 'LDA topics'])\n",
    "    partitionsData2.select('cluster', 'LDA topics').show(truncate=False)\n",
    "    return partitionsData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def topics_with_ml(communities, part_cat_dict):\n",
    "    df_ = []\n",
    "    for p in part_cat_dict:\n",
    "        df_.append((p, ' '.join(part_cat_dict[p]).replace('_', ' ').replace(',', '')\\\n",
    "                    .replace('\\\\\\'', ' ').replace('(', '').replace(')', '').lower()))\n",
    "\n",
    "    partitionsData = spark.createDataFrame(df_, ['cluster', 'categories'])\n",
    "\n",
    "    tokenized = tokenize(partitionsData)\n",
    "    cleaned = stop_words_remove(tokenized)\n",
    "    lemmatized = lemmatize(cleaned)\n",
    "    #stemmed = stem(lemmatized)\n",
    "    #cvModel = cv_fit(stemmed)\n",
    "    cvModel = cv_fit(lemmatized)\n",
    "    #cv = cv_transform(cvModel, stemmed)\n",
    "    cv = cv_transform(cvModel, lemmatized)\n",
    "    rescaled = idf(cv)\n",
    "    ldaModel = lda_fit(rescaled)\n",
    "    ldaTransformed = lda_transform(ldaModel, rescaled)\n",
    "    tops = show_topic_description(ldaModel, cvModel)\n",
    "    final = get_topics(communities, tops, ldaTransformed)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness_centrality_nodes(graph, clusters_dict):\n",
    "    res = {}\n",
    "    for e in clusters_dict:\n",
    "        H = graph.subgraph(clusters_dict[e])\n",
    "        d = nx.algorithms.centrality.betweenness_centrality_subset(H, H.nodes, H.nodes)\n",
    "        \n",
    "        m = 0\n",
    "        n = None\n",
    "        for i in d:\n",
    "            if d[i] > m:\n",
    "                m = d[i]\n",
    "                n = i\n",
    "        res.setdefault(e, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pagerank(dir_graph, clusters_dict):\n",
    "    pr = nx.algorithms.link_analysis.pagerank_alg.pagerank(dir_graph)\n",
    "    res = {}\n",
    "    for i in clusters_dict:\n",
    "        m = 0\n",
    "        n = None\n",
    "        for p in clusters_dict[i]:\n",
    "            if pr[p] > m:\n",
    "                m = pr[p]\n",
    "                n = p\n",
    "        res.setdefault(i, n)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pagerank_on_clusters(dir_graph, clusters_dict):\n",
    "    res = {}\n",
    "    for e in clusters_dict:\n",
    "        H = dir_graph.subgraph(clusters_dict[e])\n",
    "        pr = nx.algorithms.link_analysis.pagerank_alg.pagerank(H)\n",
    "        m = 0\n",
    "        n = None\n",
    "        for i in clusters_dict[e]:\n",
    "            if pr[i] > m:\n",
    "                m = pr[i]\n",
    "                n = i\n",
    "        res.setdefault(e, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_degree(graph, clusters_dict):\n",
    "    d = graph.degree\n",
    "    res = {}\n",
    "    for i in clusters_dict:\n",
    "        m = 0\n",
    "        n = None\n",
    "        for p in clusters_dict[i]:\n",
    "            if d[p] > m:\n",
    "                m = d[p]\n",
    "                n = p\n",
    "        res.setdefault(i, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_degree_on_clusters(graph, clusters_dict):\n",
    "    res = {}\n",
    "    for e in clusters_dict:\n",
    "        H = graph.subgraph(clusters_dict[e])\n",
    "        d = H.degree\n",
    "        m = 0\n",
    "        n = None\n",
    "        for p in clusters_dict[e]:\n",
    "            if d[p] > m:\n",
    "                m = d[p]\n",
    "                n = p\n",
    "        res.setdefault(e, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column(df, c, name:str, typ):\n",
    "    def get_el(i):\n",
    "        return c[i]\n",
    "    \n",
    "    udf_get_el = udf(get_el, typ)\n",
    "    \n",
    "    a = df.withColumn(name, udf_get_el('cluster'))\n",
    "    \n",
    "    #a.show()\n",
    "    \n",
    "    return a\n",
    "\n",
    "def add_columns(df, l):\n",
    "    r = df\n",
    "    for col, tag in l:\n",
    "        r = add_column(r, col, tag, StringType())\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ayman/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark warehouse set to : /home/ayman/warehouse\n",
      "importing graph from : graphs/peaks_graph_20190901_20190915.gexf\n",
      "cleaning graph\n",
      "remaining nodes : 1009\n",
      "largest connected component\n",
      "remaining nodes : 776\n",
      "detcted 38 communities\n",
      "getting 20 largest communities\n",
      "new number of nodes is : 662\n",
      "tokenizing\n",
      "stopWords removal\n",
      "lemmatization\n",
      "countVectorizer\n",
      "IDF\n",
      "training LDA\n",
      "LDA transformation\n",
      "Topic 0:\n",
      "['space', 'moon', 'indian', 'engineer', 'astronaut']\n",
      "Topic 1:\n",
      "['japan–korea', 'batting', '2009', 'painting', 'paducah']\n",
      "Topic 2:\n",
      "['space', 'moon', 'astronaut', 'indian', 'engineering']\n",
      "Topic 3:\n",
      "['11', 'attack', '2001', 'september', 'terrorism']\n",
      "Topic 4:\n",
      "['murderer', 'arabian', 'saudi', 'suicide', 'maryland']\n",
      "Topic 5:\n",
      "['all-stars', 'photography', 'maharashtrian', 'whitehaven', 'appalachian']\n",
      "Topic 6:\n",
      "['zimbabwe', 'zimbabwean', 'rhodesia', 'africa', 'tennis']\n",
      "Topic 7:\n",
      "['bird', 'character', 'painting', 'painter', 'fictional']\n",
      "Topic 8:\n",
      "['persecution', 'indonesia', 'volou', 'asturian', 'calgary']\n",
      "Topic 9:\n",
      "['series', 'game', 'film', 'comedy', 'television']\n",
      "Topic 10:\n",
      "['footballer', 'involving', 'driver', 'player', 'formula']\n",
      "Topic 11:\n",
      "['carolina', 'treaty', '1912', '1901', 'conflict']\n",
      "Topic 12:\n",
      "['parliamentary', 'emotion', 'christianity', 'albany', '2011']\n",
      "Topic 13:\n",
      "['fia', 'japanese', 'gp3', '2.0', 'f4']\n",
      "Topic 14:\n",
      "['quartet', '1948', 'country', 'musical', 'spanish-language']\n",
      "Topic 15:\n",
      "['russia', 'dáil', 'youtubers', 'liberal', 'blogger']\n",
      "Topic 16:\n",
      "['venue', 'saxony', 'f.c.', '1819', 'skagway']\n",
      "Topic 17:\n",
      "['mp', 'uk', 'constituency', 'kingdom', '2017–']\n",
      "Topic 18:\n",
      "['zimbabwe', 'zimbabwean', 'rhodesia', 'africa', 'african']\n",
      "Topic 19:\n",
      "['album', 'daniel', 'johnston', 'film', 'canadian']\n",
      "+-------+-----------------------------------------------------+\n",
      "|cluster|LDA topics                                           |\n",
      "+-------+-----------------------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–             |\n",
      "|1      |11 - attack - 2001 - september - terrorism           |\n",
      "|2      |carolina - treaty - 1912 - 1901 - conflict           |\n",
      "|3      |quartet - 1948 - country - musical - spanish-language|\n",
      "|4      |album - daniel - johnston - film - canadian          |\n",
      "|5      |series - game - film - comedy - television           |\n",
      "|6      |zimbabwe - zimbabwean - rhodesia - africa - tennis   |\n",
      "|7      |footballer - involving - driver - player - formula   |\n",
      "|8      |footballer - involving - driver - player - formula   |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–             |\n",
      "|10     |space - moon - indian - engineer - astronaut         |\n",
      "|11     |11 - attack - 2001 - september - terrorism           |\n",
      "|12     |album - daniel - johnston - film - canadian          |\n",
      "|13     |footballer - involving - driver - player - formula   |\n",
      "|14     |bird - character - painting - painter - fictional    |\n",
      "|15     |zimbabwe - zimbabwean - rhodesia - africa - tennis   |\n",
      "|16     |russia - dáil - youtubers - liberal - blogger        |\n",
      "|17     |album - daniel - johnston - film - canadian          |\n",
      "|18     |fia - japanese - gp3 - 2.0 - f4                      |\n",
      "|19     |carolina - treaty - 1912 - 1901 - conflict           |\n",
      "+-------+-----------------------------------------------------+\n",
      "\n",
      "betweenness central nodes visualization\n",
      "+-------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "|cluster|LDA topics                                           |betweenness central node                             |\n",
      "+-------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–             |Justine_Greening                                     |\n",
      "|1      |11 - attack - 2001 - september - terrorism           |United_Airlines_Flight_175                           |\n",
      "|2      |carolina - treaty - 1912 - 1901 - conflict           |September_6                                          |\n",
      "|3      |quartet - 1948 - country - musical - spanish-language|2019                                                 |\n",
      "|4      |album - daniel - johnston - film - canadian          |Sarah_Palin                                          |\n",
      "|5      |series - game - film - comedy - television           |Film                                                 |\n",
      "|6      |zimbabwe - zimbabwean - rhodesia - africa - tennis   |Zimbabwe                                             |\n",
      "|7      |footballer - involving - driver - player - formula   |September_3                                          |\n",
      "|8      |footballer - involving - driver - player - formula   |La_Liga                                              |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–             |2019_Speaker_of_the_British_House_of_Commons_election|\n",
      "|10     |space - moon - indian - engineer - astronaut         |Indian_Space_Research_Organisation                   |\n",
      "|11     |11 - attack - 2001 - september - terrorism           |United_Airlines_Flight_93                            |\n",
      "|12     |album - daniel - johnston - film - canadian          |Daniel_Johnston                                      |\n",
      "|13     |footballer - involving - driver - player - formula   |September_10                                         |\n",
      "|14     |bird - character - painting - painter - fictional    |Josh_Weinstein                                       |\n",
      "|15     |zimbabwe - zimbabwean - rhodesia - africa - tennis   |Shanghai_Masters_(tennis)                            |\n",
      "|16     |russia - dáil - youtubers - liberal - blogger        |Juncker_Commission                                   |\n",
      "|17     |album - daniel - johnston - film - canadian          |Demi_Moore                                           |\n",
      "|18     |fia - japanese - gp3 - 2.0 - f4                      |Giuliano_Alesi                                       |\n",
      "|19     |carolina - treaty - 1912 - 1901 - conflict           |Robert_Pittenger                                     |\n",
      "+-------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "\n",
      "max pagerank visualization\n",
      "+-------+-----------------------------------------------------+-----------------------------------------------------------------------+\n",
      "|cluster|LDA topics                                           |max pagerank                                                           |\n",
      "+-------+-----------------------------------------------------+-----------------------------------------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–             |Jane_Dodds                                                             |\n",
      "|1      |11 - attack - 2001 - september - terrorism           |Artwork_damaged_or_destroyed_in_the_September_11_attacks               |\n",
      "|2      |carolina - treaty - 1912 - 1901 - conflict           |1950_United_States_Senate_election_in_California                       |\n",
      "|3      |quartet - 1948 - country - musical - spanish-language|Sinking_of_MV_Conception                                               |\n",
      "|4      |album - daniel - johnston - film - canadian          |Azealia_Banks                                                          |\n",
      "|5      |series - game - film - comedy - television           |List_of_international_goals_scored_by_Lionel_Messi                     |\n",
      "|6      |zimbabwe - zimbabwean - rhodesia - africa - tennis   |Canaan_Banana                                                          |\n",
      "|7      |footballer - involving - driver - player - formula   |Victoria_Cross                                                         |\n",
      "|8      |footballer - involving - driver - player - formula   |Todd_Cantwell                                                          |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–             |2019_Speaker_of_the_British_House_of_Commons_election                  |\n",
      "|10     |space - moon - indian - engineer - astronaut         |Beresheet                                                              |\n",
      "|11     |11 - attack - 2001 - september - terrorism           |Hamza_al-Ghamdi                                                        |\n",
      "|12     |album - daniel - johnston - film - canadian          |Hi,_How_Are_You_Daniel_Johnston?                                       |\n",
      "|13     |footballer - involving - driver - player - formula   |Battle_of_Baltimore                                                    |\n",
      "|14     |bird - character - painting - painter - fictional    |The_Simpsons_(season_9)                                                |\n",
      "|15     |zimbabwe - zimbabwean - rhodesia - africa - tennis   |2019_Moselle_Open_–_Singles                                            |\n",
      "|16     |russia - dáil - youtubers - liberal - blogger        |2019_Russian_elections                                                 |\n",
      "|17     |album - daniel - johnston - film - canadian          |John_Alexander_(artist)                                                |\n",
      "|18     |fia - japanese - gp3 - 2.0 - f4                      |2019_Spa-Francorchamps_FIA_Formula_2_round                             |\n",
      "|19     |carolina - treaty - 1912 - 1901 - conflict           |2018_United_States_House_of_Representatives_elections_in_North_Carolina|\n",
      "+-------+-----------------------------------------------------+-----------------------------------------------------------------------+\n",
      "\n",
      "max pagerank2 visualization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------------------------+-----------------------------------------------------------------------+\n",
      "|cluster|LDA topics                                           |max isolated pagerank                                                  |\n",
      "+-------+-----------------------------------------------------+-----------------------------------------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–             |Jane_Dodds                                                             |\n",
      "|1      |11 - attack - 2001 - september - terrorism           |Artwork_damaged_or_destroyed_in_the_September_11_attacks               |\n",
      "|2      |carolina - treaty - 1912 - 1901 - conflict           |1950_United_States_Senate_election_in_California                       |\n",
      "|3      |quartet - 1948 - country - musical - spanish-language|Sinking_of_MV_Conception                                               |\n",
      "|4      |album - daniel - johnston - film - canadian          |2012_Benghazi_attack                                                   |\n",
      "|5      |series - game - film - comedy - television           |List_of_international_goals_scored_by_Lionel_Messi                     |\n",
      "|6      |zimbabwe - zimbabwean - rhodesia - africa - tennis   |Canaan_Banana                                                          |\n",
      "|7      |footballer - involving - driver - player - formula   |Victoria_Cross                                                         |\n",
      "|8      |footballer - involving - driver - player - formula   |Todd_Cantwell                                                          |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–             |2019_Speaker_of_the_British_House_of_Commons_election                  |\n",
      "|10     |space - moon - indian - engineer - astronaut         |Beresheet                                                              |\n",
      "|11     |11 - attack - 2001 - september - terrorism           |Hamza_al-Ghamdi                                                        |\n",
      "|12     |album - daniel - johnston - film - canadian          |Hi,_How_Are_You_Daniel_Johnston?                                       |\n",
      "|13     |footballer - involving - driver - player - formula   |Battle_of_Baltimore                                                    |\n",
      "|14     |bird - character - painting - painter - fictional    |The_Simpsons_(season_9)                                                |\n",
      "|15     |zimbabwe - zimbabwean - rhodesia - africa - tennis   |2019_Moselle_Open_–_Singles                                            |\n",
      "|16     |russia - dáil - youtubers - liberal - blogger        |2019_Russian_elections                                                 |\n",
      "|17     |album - daniel - johnston - film - canadian          |John_Alexander_(artist)                                                |\n",
      "|18     |fia - japanese - gp3 - 2.0 - f4                      |2019_Spa-Francorchamps_FIA_Formula_2_round                             |\n",
      "|19     |carolina - treaty - 1912 - 1901 - conflict           |2018_United_States_House_of_Representatives_elections_in_North_Carolina|\n",
      "+-------+-----------------------------------------------------+-----------------------------------------------------------------------+\n",
      "\n",
      "max deg visualization\n",
      "+-------+-----------------------------------------------------+---------------------------------------+\n",
      "|cluster|LDA topics                                           |max degree                             |\n",
      "+-------+-----------------------------------------------------+---------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–             |Dominic_Grieve                         |\n",
      "|1      |11 - attack - 2001 - september - terrorism           |United_Airlines_Flight_175             |\n",
      "|2      |carolina - treaty - 1912 - 1901 - conflict           |September_6                            |\n",
      "|3      |quartet - 1948 - country - musical - spanish-language|2019                                   |\n",
      "|4      |album - daniel - johnston - film - canadian          |John_Bolton                            |\n",
      "|5      |series - game - film - comedy - television           |Film                                   |\n",
      "|6      |zimbabwe - zimbabwean - rhodesia - africa - tennis   |Zimbabwe                               |\n",
      "|7      |footballer - involving - driver - player - formula   |September_3                            |\n",
      "|8      |footballer - involving - driver - player - formula   |La_Liga                                |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–             |Chairman_of_Ways_and_Means             |\n",
      "|10     |space - moon - indian - engineer - astronaut         |Indian_Space_Research_Organisation     |\n",
      "|11     |11 - attack - 2001 - september - terrorism           |United_Airlines_Flight_93              |\n",
      "|12     |album - daniel - johnston - film - canadian          |Daniel_Johnston                        |\n",
      "|13     |footballer - involving - driver - player - formula   |September_10                           |\n",
      "|14     |bird - character - painting - painter - fictional    |The_City_of_New_York_vs._Homer_Simpson |\n",
      "|15     |zimbabwe - zimbabwean - rhodesia - africa - tennis   |Novak_Djokovic                         |\n",
      "|16     |russia - dáil - youtubers - liberal - blogger        |Conte_II_Cabinet                       |\n",
      "|17     |album - daniel - johnston - film - canadian          |Burt_Bacharach                         |\n",
      "|18     |fia - japanese - gp3 - 2.0 - f4                      |Giuliano_Alesi                         |\n",
      "|19     |carolina - treaty - 1912 - 1901 - conflict           |North_Carolina_House_of_Representatives|\n",
      "+-------+-----------------------------------------------------+---------------------------------------+\n",
      "\n",
      "max deg2 visualization\n",
      "+-------+-----------------------------------------------------+---------------------------------------+\n",
      "|cluster|LDA topics                                           |max isolated degree                    |\n",
      "+-------+-----------------------------------------------------+---------------------------------------+\n",
      "|0      |mp - uk - constituency - kingdom - 2017–             |Nicholas_Soames                        |\n",
      "|1      |11 - attack - 2001 - september - terrorism           |Collapse_of_the_World_Trade_Center     |\n",
      "|2      |carolina - treaty - 1912 - 1901 - conflict           |September_6                            |\n",
      "|3      |quartet - 1948 - country - musical - spanish-language|2019                                   |\n",
      "|4      |album - daniel - johnston - film - canadian          |John_Bolton                            |\n",
      "|5      |series - game - film - comedy - television           |Film                                   |\n",
      "|6      |zimbabwe - zimbabwean - rhodesia - africa - tennis   |Zimbabwe                               |\n",
      "|7      |footballer - involving - driver - player - formula   |September_3                            |\n",
      "|8      |footballer - involving - driver - player - formula   |La_Liga                                |\n",
      "|9      |mp - uk - constituency - kingdom - 2017–             |Chairman_of_Ways_and_Means             |\n",
      "|10     |space - moon - indian - engineer - astronaut         |Indian_Space_Research_Organisation     |\n",
      "|11     |11 - attack - 2001 - september - terrorism           |United_Airlines_Flight_93              |\n",
      "|12     |album - daniel - johnston - film - canadian          |Daniel_Johnston                        |\n",
      "|13     |footballer - involving - driver - player - formula   |September_10                           |\n",
      "|14     |bird - character - painting - painter - fictional    |The_City_of_New_York_vs._Homer_Simpson |\n",
      "|15     |zimbabwe - zimbabwean - rhodesia - africa - tennis   |Novak_Djokovic                         |\n",
      "|16     |russia - dáil - youtubers - liberal - blogger        |Conte_II_Cabinet                       |\n",
      "|17     |album - daniel - johnston - film - canadian          |Crystal_Head_Vodka                     |\n",
      "|18     |fia - japanese - gp3 - 2.0 - f4                      |Giuliano_Alesi                         |\n",
      "|19     |carolina - treaty - 1912 - 1901 - conflict           |North_Carolina_House_of_Representatives|\n",
      "+-------+-----------------------------------------------------+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ.setdefault('JAVA_HOME', '/usr/lib/jvm/java-1.8.0-openjdk-amd64')\n",
    "user = os.environ.get('USER')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from os import walk\n",
    "\n",
    "mypath = 'graphs/'\n",
    "max_num_communities = 20\n",
    "output_path = 'output/'\n",
    "#(_, _, filenames) = next(walk(mypath))\n",
    "filenames = [\"peaks_graph_20190901_20190915.gexf\"]\n",
    "\n",
    "global driver\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=('neo4j', 'tototo'))\n",
    "\n",
    "global spark\n",
    "spark = SparkSession.builder.appName('graph processing').config(\"spark.master\", \"local[*]\").config(\"spark.sql.warehouse.dir\", \"/home/\"+user+\"/warehouse\").getOrCreate()\n",
    "print(\"Spark warehouse set to :\", spark.conf.get('spark.sql.warehouse.dir'))\n",
    "\n",
    "for f in sorted(filenames):\n",
    "    path = mypath + f\n",
    "    (G_undir, G_dir, communities, part_cat_dict) = ld(path, max_num_communities)\n",
    "        \n",
    "    maxx = find_max_freq(count_all_frequencies(part_cat_dict))\n",
    "    \n",
    "    lda_df = topics_with_ml(communities, part_cat_dict)\n",
    "    \n",
    "    betweenness_central_nodes = betweenness_centrality_nodes(G_undir, communities)\n",
    "    \n",
    "    pr_result = max_pagerank(G_dir, communities)\n",
    "    pr_iso_result = max_pagerank_on_clusters(G_dir, communities)\n",
    "    \n",
    "    deg_result = max_degree(G_undir, communities)\n",
    "    deg_iso_result = max_degree_on_clusters(G_undir, communities)\n",
    "    \n",
    "    res = add_columns(lda_df,[(betweenness_central_nodes, 'betweenness central node'),\n",
    "                              (pr_result, 'max pagerank'),\n",
    "                              (pr_iso_result, 'max isolated pagerank'),\n",
    "                              (deg_result, 'max degree'),\n",
    "                              (deg_iso_result, 'max isolated degree'),\n",
    "                              (maxx, 'max category')])    \n",
    "    \n",
    "    print('betweenness central nodes visualization')\n",
    "    res.select('cluster', 'LDA topics', 'betweenness central node').show(truncate=False)\n",
    "    print('max pagerank visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max pagerank').show(truncate=False)\n",
    "    print('max pagerank2 visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max isolated pagerank').show(truncate=False)\n",
    "    print('max deg visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max degree').show(truncate=False)\n",
    "    print('max deg2 visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max isolated degree').show(truncate=False)\n",
    "    \n",
    "    name = f[12:-5]\n",
    "    path = output_path+name+\"/\"\n",
    "    res.coalesce(1).write.csv(path, mode = 'overwrite')\n",
    "    nx.write_gexf(G_undir, path+name+\".gexf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insider_neighbors_ratio(G, communities, ls):\n",
    "    res = {}\n",
    "    for cluster in ls:\n",
    "        node = ls[cluster]\n",
    "        neighbors = list(nx.classes.function.neighbors(G, node))\n",
    "        community_nodes = communities[cluster]\n",
    "        count = 0\n",
    "    \n",
    "        for n in neighbors:\n",
    "            if n in community_nodes:\n",
    "                count-=-1 #why not ;p\n",
    "    \n",
    "        ratio = \"{0:.2f}\".format(100 * count / len(neighbors))+'%'\n",
    "    \n",
    "        print(cluster, node, ratio)\n",
    "    \n",
    "        res.setdefault(cluster, (node, ratio))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, deg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, pr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, pr2_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''print('betweenness central nodes visualization')\n",
    "res.select('cluster', 'LDA topics', 'betweenness central node').show(truncate=False)\n",
    "print('max pagerank visualization')\n",
    "res.select('cluster', 'LDA topics', 'max pagerank').show(truncate=False)\n",
    "print('max pagerank2 visualization')\n",
    "res.select('cluster', 'LDA topics', 'max isolated pagerank').show(truncate=False)\n",
    "print('max deg visualization')\n",
    "res.select('cluster', 'LDA topics', 'max degree').show(truncate=False)\n",
    "print('max deg2 visualization')\n",
    "res.select('cluster', 'LDA topics', 'max isolated degree').show(truncate=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''import argparse\n",
    "\n",
    "def parseArguments():\n",
    "    # Create argument parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Optional arguments\n",
    "    parser.add_argument(\"-jdk8\", \"--jdk8Path\", help=\"path to jdk8. Default : /usr/lib/jvm/java-1.8.0-openjdk-amd64\", type=str, default='/usr/lib/jvm/java-1.8.0-openjdk-amd64')\n",
    "    parser.add_argument(\"-n4jadr\", \"--neo4jAddress\", help=\"neo4j database address. Default : bolt://localhost:7687\", type=str, default='bolt://localhost:7687')\n",
    "    parser.add_argument(\"-n4jusr\", \"--neo4jUsername\", help=\"neo4j database username. Default : neo4j\", type=str, default='neo4j')\n",
    "    parser.add_argument(\"-n4jpwd\", \"--neo4jPassword\", help=\"neo4j database password. Default : neo4j\", type=str, default='neo4j')\n",
    "    parser.add_argument(\"-ip\", \"--inputPath\", help=\"path of the directory containing the graphs. Default : graphs/\", type=str, default='graphs/')\n",
    "    parser.add_argument(\"-n\", \"--nOfClusters\", help=\"max number of clusters to extract. Default : 20\", type=int, default=20)\n",
    "    parser.add_argument(\"-op\", \"--outputPath\", help=\"path of the output directory. Default : output/\", type=str, default='output/')\n",
    "\n",
    "    # Parse arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "    \n",
    "main(parseArguments())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more centrality attributes: pagerank, degrees, and try to find others\n",
    "\n",
    "make code a sort of an executable tool with arguments etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take node with highest degree in each cluster and find its neighbors and seee how many are in the same cluster\n",
    "==> the second variant (using just insiders to compute deg and pagerank) has better ratios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
