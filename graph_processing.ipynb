{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import community\n",
    "\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "from neo4j import GraphDatabase, Driver\n",
    "\n",
    "import pyspark.ml\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import IDF, Tokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_graph(path):\n",
    "    print('importing graph from :', path)\n",
    "    directed_g = nx.read_gexf(path, node_type=None, relabel=True)\n",
    "    undirected_g = directed_g.to_undirected()\n",
    "    return undirected_g, directed_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_graph(g):\n",
    "    print('number of nodes : ' + str(len(g)))\n",
    "    fig, ax = plt.subplots(figsize=(70, 50)) # set size\n",
    "    nx.draw(g, with_labels=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_graph(graph):\n",
    "    print('cleaning graph')\n",
    "    #Degree computation\n",
    "    nodes_with_degrees = graph.degree\n",
    "    #mean\n",
    "    mean_deg = statistics.mean(l[1] for l in nodes_with_degrees)\n",
    "    #std\n",
    "    std_deg = statistics.stdev(l[1] for l in nodes_with_degrees)\n",
    "    #threshold\n",
    "    threshold = mean_deg + std_deg*std_deg/2 \n",
    "\n",
    "    #Filtering extremely highly connected nodes\n",
    "    nodes_to_remove = list(filter(lambda d : d[1] > threshold, nodes_with_degrees))\n",
    "    n,d = zip(*nodes_to_remove)\n",
    "    graph.remove_nodes_from(n)\n",
    "    \n",
    "    #Filtering isolated nodes\n",
    "    nodes_with_degrees = graph.degree\n",
    "    nodes_to_remove = list(filter(lambda d : d[1] == 0, nodes_with_degrees))\n",
    "    n,d = zip(*nodes_to_remove)\n",
    "    graph.remove_nodes_from(n)\n",
    "\n",
    "    print('remaining nodes : ' + str(len(graph)))\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only largest connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_connected_component(graph):\n",
    "    print('largest connected component')\n",
    "    gcc = max(nx.connected_component_subgraphs(graph), key=len)\n",
    "    print('remaining nodes : ' + str(len(gcc)))\n",
    "    return gcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning using Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communities_louvain(graph):\n",
    "    louvain_communities = community.best_partition(graph, resolution=1)\n",
    "    louvain_communities_dict = {}\n",
    "    for key, value in sorted(louvain_communities.items()):\n",
    "        louvain_communities_dict.setdefault(value, []).append(key)\n",
    "\n",
    "    print('detcted',len(louvain_communities_dict),'communities')\n",
    "    \n",
    "    return louvain_communities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning using Leiden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/leidenalg/\n",
    "https://www.nature.com/articles/s41598-019-41695-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leiden helpers/adapters\n",
    "def get_id_to_title(graph):\n",
    "    tmp = nx.get_node_attributes(graph, 'id')\n",
    "    d = {}\n",
    "    for x in tmp:\n",
    "        d.setdefault(tmp[x], x)\n",
    "    return d\n",
    "\n",
    "def nx_to_ig(graph):\n",
    "    nx.write_graphml(graph,'graph.graphml')\n",
    "    graphi = ig.read('graph.graphml',format=\"graphml\")\n",
    "    os.remove('graph.graphml')\n",
    "    return graphi\n",
    "\n",
    "def translate_leiden_to_dict(partition, graphi, dictionary):\n",
    "    nodes = graphi.vs\n",
    "    res = {}\n",
    "    for i in range(len(partition)):\n",
    "        res.setdefault(i, [])\n",
    "        for v in partition[i]:\n",
    "            res[i].append(dictionary[nodes[v]['id']])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communities_leiden(graph):\n",
    "    graphi = nx_to_ig(graph)\n",
    "    partition = la.find_partition(graphi, la.CPMVertexPartition, resolution_parameter = 0.01)#0.01 was good\n",
    "    dictionary = get_id_to_title(graph)\n",
    "    res = translate_leiden_to_dict(partition, graphi, dictionary)\n",
    "    \n",
    "    print('detcted',len(res),'communities')\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categoriy of each partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of categories of a page\n",
    "def get_categories(page_name):\n",
    "    c = list()\n",
    "    with driver.session() as session:\n",
    "        with session.begin_transaction() as tx:\n",
    "            for record in tx.run(\"MATCH (p:Page)-[:BELONGS_TO]->(c:Category) \"\n",
    "                                 \"WHERE p.title = {page_name} \"\n",
    "                                 \"AND NOT exists((c)-[:BELONGS_TO]->(:Category {title: \\'{hc}\\'})) \"\n",
    "                                 \"RETURN c.title\", \n",
    "                                 page_name = page_name,\n",
    "                                 hc = language_mapper[language]):\n",
    "                #print(record[\"c.title\"])\n",
    "                c.append(record[\"c.title\"])\n",
    "    return c\n",
    "\n",
    "#map each element to frequency in a list    \n",
    "def count_frequency(my_list): \n",
    "      \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    for items in my_list: \n",
    "        freq[items] = my_list.count(items)\n",
    "    return freq\n",
    "\n",
    "#iterate over pages dict partition\n",
    "def part_category_fetch(key, dic):\n",
    "    cat = []\n",
    "    for title in dic[key]:\n",
    "        cat += get_categories(title)\n",
    "    #print('done fetching')\n",
    "    return cat\n",
    "\n",
    "def fetcher(bpd):\n",
    "    part_cat = {}\n",
    "    \n",
    "    for part in sorted(bpd):\n",
    "        #print(part)\n",
    "        cat = part_category_fetch(part, bpd)\n",
    "        #print(cat)\n",
    "        part_cat.setdefault(part, cat)\n",
    "    \n",
    "    return part_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch categories for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_categories(bpd):\n",
    "    part_cat_dict = fetcher(bpd)\n",
    "    \n",
    "    return part_cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_frequencies(d):\n",
    "    part_cat_dict_freq = {}\n",
    "    for e in d:\n",
    "        cat_map_freq = count_frequency(d[e])\n",
    "        part_cat_dict_freq.setdefault(e, cat_map_freq)\n",
    "    return part_cat_dict_freq\n",
    " \n",
    "def find_max_freq(p):\n",
    "    max_part_cat = {}\n",
    "    for e in p:\n",
    "        ls = list(p[e].keys())\n",
    "        cat = ls[0]\n",
    "        for x in ls:\n",
    "            if p[e][cat] < p[e][x]:\n",
    "                cat = x\n",
    "        max_part_cat.setdefault(e, cat)\n",
    "    return max_part_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_largest_communities(c, n):\n",
    "    x = min(n, len(c))\n",
    "    print('getting', x, 'largest communities')\n",
    "    \n",
    "    l = []\n",
    "    for e in sorted(c):\n",
    "        l.append(c[e])\n",
    "    \n",
    "    tmp = sorted(l, key=len, reverse=True)[:x]\n",
    "    \n",
    "    res = {}\n",
    "    for i in range(x):\n",
    "        res.setdefault(i, tmp[i])\n",
    "    \n",
    "    length = 0\n",
    "    for e in res:\n",
    "        length += len(res[e])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ld(path, n):\n",
    "    undirected_g, directed_g = import_graph(path)\n",
    "    #verify_graph(g)\n",
    "    gg = largest_connected_component(clean_graph(undirected_g))\n",
    "    #verify_graph(gg)\n",
    "    \n",
    "    #communities_dict = communities_louvain(gg)\n",
    "    communities_dict = communities_leiden(gg)\n",
    "    \n",
    "    communities = get_n_largest_communities(communities_dict, n)\n",
    "    \n",
    "    undirected_graph = gg.subgraph([x for y in communities.values() for x in y])\n",
    "    directed_graph = directed_g.subgraph([x for y in communities.values() for x in y])\n",
    "        \n",
    "    print('new number of nodes is :', len(directed_graph))\n",
    "    \n",
    "    part_cat_dict = fetch_categories(communities)\n",
    "    \n",
    "    return undirected_graph, directed_graph, communities, part_cat_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "    print('tokenizing')\n",
    "    tokenizer = Tokenizer(inputCol=\"categories\", outputCol=\"raw\")\n",
    "    res = tokenizer.transform(df)\n",
    "    return res\n",
    "    \n",
    "def stop_words_remove(df):\n",
    "    print('stopWords removal')\n",
    "    remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"words\")\n",
    "    res = remover.transform(df)\n",
    "    return res\n",
    "\n",
    "def lemmatize(df):\n",
    "    print('lemmatization')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatizer_udf = udf(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens], T.ArrayType(T.StringType()))\n",
    "    res = df.withColumn(\"words\", lemmatizer_udf(\"words\"))\n",
    "    return res\n",
    "\n",
    "def lemmatize_new(df):\n",
    "    #nlp = spacy.load(language_mapper[language]['lemmatizer'])\n",
    "    print('new lemmatization')\n",
    "\n",
    "    nlp = spacy.load('fr_core_news_sm')\n",
    "    lemmatizer_udf = udf(lambda tokens: [' '.join([w.lemma_ for w in nlp(token)]) for token in tokens], T.ArrayType(T.StringType()))\n",
    "    res = df.withColumn(\"words\", lemmatizer_udf(\"words\"))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def stem(df):\n",
    "    print('stemming')\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], T.ArrayType(T.StringType()))\n",
    "    res = df.withColumn(\"words\", stemmer_udf(\"words\"))\n",
    "    return res\n",
    "\n",
    "def cv_fit(df):\n",
    "    print('countVectorizer')\n",
    "    countVectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "    cvmodel = countVectorizer.fit(df)\n",
    "    return cvmodel\n",
    "\n",
    "def cv_transform(cvmodel, df):\n",
    "    res = cvmodel.transform(df)\n",
    "    return res\n",
    "\n",
    "def idf(df):\n",
    "    print('IDF')\n",
    "    idf_ = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf_.fit(df)\n",
    "    res = idfModel.transform(df)\n",
    "    return res\n",
    "    \n",
    "    #dataset = rescaledData.select('cluster','categories', 'features')\n",
    "    #print(dataset)\n",
    "\n",
    "    #dataset.show(truncate=False)\n",
    "    \n",
    "def lda_fit(df):\n",
    "    # Trains a LDA model.\n",
    "    print('training LDA')\n",
    "    lda_ = LDA(k=df.count(), maxIter=100)\n",
    "    ldaModel = lda_.fit(df)\n",
    "    return ldaModel\n",
    "\n",
    "def lda_transform(ldaModel, df):\n",
    "    print('LDA transformation')\n",
    "    transformed = ldaModel.transform(df)\n",
    "    #transformed.show()\n",
    "    return transformed\n",
    "    \n",
    "#    l = transformed.select('topicDistribution').first()[0]\n",
    "#    print(transformed.first())\n",
    "#    m = list(l).index(max(l))\n",
    "#    print('\\ntopic index is :',m)\n",
    "#    print(topics.take(m+1)[m])\n",
    "    \n",
    "def show_topic_description(ldaModel, cvmodel):\n",
    "    topicIndices = ldaModel.describeTopics(maxTermsPerTopic = 5)\n",
    "    vocabList = cvmodel.vocabulary\n",
    "    tops = []\n",
    "    for i,t,w in topicIndices.collect():\n",
    "        print('Topic %d:' % i)\n",
    "        entry = []\n",
    "        for j in range(len(t)):\n",
    "            entry.append(vocabList[t[j]])\n",
    "            #print('\\t', vocabList[t[j]], w[j])\n",
    "        print(entry)\n",
    "        tops.append(entry)\n",
    "        \n",
    "    return tops\n",
    "    \n",
    "def get_topics(communities, tops, transformed):\n",
    "    cluster_topicDist = sorted(transformed.select('cluster', 'topicDistribution').collect())\n",
    "    cluster_topicTerms = []\n",
    "    for e in cluster_topicDist:\n",
    "        m = list(e[1]).index(max(e[1]))\n",
    "        cluster_topicTerms.append(tops[m])\n",
    "\n",
    "    df2_ = []\n",
    "    for k in sorted(communities.keys()):\n",
    "        df2_.append((k, ' - '.join(communities[k]), ' - '.join(cluster_topicTerms[k])))\n",
    "    \n",
    "    partitionsData2 = spark.createDataFrame(df2_, ['cluster', 'page names', 'LDA topics'])\n",
    "    partitionsData2.select('cluster', 'LDA topics').show(truncate=False)\n",
    "    return partitionsData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(part_cat_dict):\n",
    "    df_ = []\n",
    "    for p in part_cat_dict:\n",
    "        df_.append((p, ' '.join(part_cat_dict[p]).replace('_', ' ').replace(',', '')\\\n",
    "                    .replace('\\\\\\'', ' ').replace('(', '').replace(')', '').replace('–',' ').lower()))\n",
    "\n",
    "    partitionsData = spark.createDataFrame(df_, ['cluster', 'categories'])\n",
    "    return partitionsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def topics_with_ml(communities, part_cat_dict):\n",
    "    \n",
    "    partitionsData = create_df(part_cat_dict)\n",
    "    tokenized = tokenize(partitionsData)\n",
    "    cleaned = stop_words_remove(tokenized)\n",
    "    \n",
    "    if (language == 'en'):\n",
    "        lemmatized = lemmatize(cleaned)\n",
    "    else:\n",
    "        lemmatized = lemmatize_new(cleaned)\n",
    "    \n",
    "    #stemmed = stem(lemmatized)\n",
    "    #cvModel = cv_fit(stemmed)\n",
    "    cvModel = cv_fit(lemmatized)\n",
    "    #cv = cv_transform(cvModel, stemmed)\n",
    "    cv = cv_transform(cvModel, lemmatized)\n",
    "    rescaled = idf(cv)\n",
    "    ldaModel = lda_fit(rescaled)\n",
    "    ldaTransformed = lda_transform(ldaModel, rescaled)\n",
    "    tops = show_topic_description(ldaModel, cvModel)\n",
    "    final = get_topics(communities, tops, ldaTransformed)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness_centrality_nodes(graph, clusters_dict):\n",
    "    res = {}\n",
    "    for e in clusters_dict:\n",
    "        H = graph.subgraph(clusters_dict[e])\n",
    "        d = nx.algorithms.centrality.betweenness_centrality_subset(H, H.nodes, H.nodes)\n",
    "        \n",
    "        m = 0\n",
    "        n = None\n",
    "        for i in d:\n",
    "            if d[i] > m:\n",
    "                m = d[i]\n",
    "                n = i\n",
    "        res.setdefault(e, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pagerank(dir_graph, clusters_dict):\n",
    "    pr = nx.algorithms.link_analysis.pagerank_alg.pagerank(dir_graph)\n",
    "    res = {}\n",
    "    for i in clusters_dict:\n",
    "        m = 0\n",
    "        n = None\n",
    "        for p in clusters_dict[i]:\n",
    "            if pr[p] > m:\n",
    "                m = pr[p]\n",
    "                n = p\n",
    "        res.setdefault(i, n)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pagerank_on_clusters(dir_graph, clusters_dict):\n",
    "    res = {}\n",
    "    for e in clusters_dict:\n",
    "        H = dir_graph.subgraph(clusters_dict[e])\n",
    "        pr = nx.algorithms.link_analysis.pagerank_alg.pagerank(H)\n",
    "        m = 0\n",
    "        n = None\n",
    "        for i in clusters_dict[e]:\n",
    "            if pr[i] > m:\n",
    "                m = pr[i]\n",
    "                n = i\n",
    "        res.setdefault(e, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_degree(graph, clusters_dict):\n",
    "    d = graph.degree\n",
    "    res = {}\n",
    "    for i in clusters_dict:\n",
    "        m = 0\n",
    "        n = None\n",
    "        for p in clusters_dict[i]:\n",
    "            if d[p] > m:\n",
    "                m = d[p]\n",
    "                n = p\n",
    "        res.setdefault(i, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_degree_on_clusters(graph, clusters_dict):\n",
    "    res = {}\n",
    "    for e in clusters_dict:\n",
    "        H = graph.subgraph(clusters_dict[e])\n",
    "        d = H.degree\n",
    "        m = 0\n",
    "        n = None\n",
    "        for p in clusters_dict[e]:\n",
    "            if d[p] > m:\n",
    "                m = d[p]\n",
    "                n = p\n",
    "        res.setdefault(e, n)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column(df, c, name:str, typ):\n",
    "    def get_el(i):\n",
    "        return c[i]\n",
    "    \n",
    "    udf_get_el = udf(get_el, typ)\n",
    "    \n",
    "    a = df.withColumn(name, udf_get_el('cluster'))\n",
    "    \n",
    "    #a.show()\n",
    "    \n",
    "    return a\n",
    "\n",
    "def add_columns(df, l):\n",
    "    r = df\n",
    "    for col, tag in l:\n",
    "        r = add_column(r, col, tag, T.StringType())\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_attributes_from_df(graph, df):\n",
    "    rowList = df.collect()\n",
    "    d = {}\n",
    "    for row in rowList:\n",
    "        for p in row[1].split(\" - \"):\n",
    "            d.setdefault(p, {\"community\": row[0], \"lda\": row[2]})\n",
    "            \n",
    "    nx.set_node_attributes(graph, d)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ayman/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access UI on : http://0.0.0.0:4040\n",
      "Spark warehouse set to : /home/ayman/warehouse\n",
      "importing graph from : graphs/en/peaks_graph_20180901_20180915.gexf\n",
      "cleaning graph\n",
      "remaining nodes : 4484\n",
      "largest connected component\n",
      "remaining nodes : 4196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/igraph/__init__.py:2223: RuntimeWarning: Could not add vertex ids, there is already an 'id' vertex attribute at foreign-graphml.c:443\n",
      "  return reader(f, *args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detcted 258 communities\n",
      "getting 20 largest communities\n",
      "new number of nodes is : 1321\n",
      "tokenizing\n",
      "stopWords removal\n",
      "lemmatization\n",
      "countVectorizer\n",
      "IDF\n",
      "training LDA\n",
      "LDA transformation\n",
      "Topic 0:\n",
      "['p3546', 'property', 'p3547', 'melbourne', 'all-australians']\n",
      "Topic 1:\n",
      "['mrf', 'nova', 'k', 'melbourne', '1993']\n",
      "Topic 2:\n",
      "['football', 'player', 'australian', 'broadcaster', 'league']\n",
      "Topic 3:\n",
      "['outlet', 'gridiron', 'bobsledders', 'heptathletes', 'stoke']\n",
      "Topic 4:\n",
      "['court', 'law', 'supreme', 'judge', 'lawyer']\n",
      "Topic 5:\n",
      "['hurricane', 'water', 'carolina', 'body', 'north']\n",
      "Topic 6:\n",
      "['dynamo', 'gymnastikforening', 'connecticut', 'legislation', 'locally']\n",
      "Topic 7:\n",
      "['ice', 'hockey', 'medalist', 'winter', 'draft']\n",
      "Topic 8:\n",
      "['11', 'attack', '2001', 'arabian', 'comic']\n",
      "Topic 9:\n",
      "['court', 'miss', 'pageant', 'supreme', 'america']\n",
      "Topic 10:\n",
      "['grenadian', 'racism', 'terminology', 'aik', 'britannica']\n",
      "Topic 11:\n",
      "['p3547', 'p3546', 'property', 'melbourne', 'medal']\n",
      "Topic 12:\n",
      "['formula', 'one', 'driver', 'background', 'hour']\n",
      "Topic 13:\n",
      "['footballer', 'herzegovina', 'bosnia', 'under-21', 'f.c.']\n",
      "Topic 14:\n",
      "['album', 'usage', 'miller', 'mac', 'singlechart']\n",
      "Topic 15:\n",
      "['pageant', 'miss', 'america', 'film', 'delegate']\n",
      "Topic 16:\n",
      "['formula', 'driver', 'one', 'racing', 'championship']\n",
      "Topic 17:\n",
      "['football', 'coach', 'conference', 'venue', 'season']\n",
      "Topic 18:\n",
      "['water', 'body', 'town', 'transportation', 'river']\n",
      "Topic 19:\n",
      "['packer', 'minnetonka', 'delaware', 'peace', 'bear']\n",
      "+-------+------------------------------------------------------+\n",
      "|cluster|LDA topics                                            |\n",
      "+-------+------------------------------------------------------+\n",
      "|0      |football - player - australian - broadcaster - league |\n",
      "|1      |hurricane - water - carolina - body - north           |\n",
      "|2      |p3546 - property - p3547 - melbourne - all-australians|\n",
      "|3      |hurricane - water - carolina - body - north           |\n",
      "|4      |11 - attack - 2001 - arabian - comic                  |\n",
      "|5      |football - player - australian - broadcaster - league |\n",
      "|6      |pageant - miss - america - film - delegate            |\n",
      "|7      |football - coach - conference - venue - season        |\n",
      "|8      |pageant - miss - america - film - delegate            |\n",
      "|9      |footballer - herzegovina - bosnia - under-21 - f.c.   |\n",
      "|10     |ice - hockey - medalist - winter - draft              |\n",
      "|11     |football - coach - conference - venue - season        |\n",
      "|12     |football - coach - conference - venue - season        |\n",
      "|13     |album - usage - miller - mac - singlechart            |\n",
      "|14     |football - coach - conference - venue - season        |\n",
      "|15     |formula - driver - one - racing - championship        |\n",
      "|16     |court - law - supreme - judge - lawyer                |\n",
      "|17     |football - coach - conference - venue - season        |\n",
      "|18     |football - player - australian - broadcaster - league |\n",
      "|19     |football - coach - conference - venue - season        |\n",
      "+-------+------------------------------------------------------+\n",
      "\n",
      "betweenness central nodes visualization\n",
      "+-------+------------------------------------------------------+--------------------------------------------------+\n",
      "|cluster|LDA topics                                            |betweenness central node                          |\n",
      "+-------+------------------------------------------------------+--------------------------------------------------+\n",
      "|0      |football - player - australian - broadcaster - league |Kenny_Albert                                      |\n",
      "|1      |hurricane - water - carolina - body - north           |Sandhills_(Carolina)                              |\n",
      "|2      |p3546 - property - p3547 - melbourne - all-australians|Victorian_Football_League                         |\n",
      "|3      |hurricane - water - carolina - body - north           |Subtropical_cyclone                               |\n",
      "|4      |11 - attack - 2001 - arabian - comic                  |Stonycreek_Township,_Somerset_County,_Pennsylvania|\n",
      "|5      |football - player - australian - broadcaster - league |NBCSN                                             |\n",
      "|6      |pageant - miss - america - film - delegate            |Smokey_and_the_Bandit                             |\n",
      "|7      |football - coach - conference - venue - season        |Graduate_assistant                                |\n",
      "|8      |pageant - miss - america - film - delegate            |Miss_America_1948                                 |\n",
      "|9      |footballer - herzegovina - bosnia - under-21 - f.c.   |Romania_national_under-21_football_team           |\n",
      "|10     |ice - hockey - medalist - winter - draft              |2019_NHL_Entry_Draft                              |\n",
      "|11     |football - coach - conference - venue - season        |Michigan_State–Notre_Dame_football_rivalry        |\n",
      "|12     |football - coach - conference - venue - season        |University_of_Tennessee                           |\n",
      "|13     |album - usage - miller - mac - singlechart            |Blue_Slide_Park                                   |\n",
      "|14     |football - coach - conference - venue - season        |Kidd_Brewer_Stadium                               |\n",
      "|15     |formula - driver - one - racing - championship        |Lewis_Hamilton                                    |\n",
      "|16     |court - law - supreme - judge - lawyer                |United_States_Senate_Committee_on_the_Judiciary   |\n",
      "|17     |football - coach - conference - venue - season        |Jones_AT&T_Stadium                                |\n",
      "|18     |football - player - australian - broadcaster - league |2015_Florida_State_Seminoles_football_team        |\n",
      "|19     |football - coach - conference - venue - season        |Stanford_Cardinal_football                        |\n",
      "+-------+------------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "max pagerank visualization\n",
      "+-------+------------------------------------------------------+--------------------------------------------------------------+\n",
      "|cluster|LDA topics                                            |max pagerank                                                  |\n",
      "+-------+------------------------------------------------------+--------------------------------------------------------------+\n",
      "|0      |football - player - australian - broadcaster - league |2016_Detroit_Lions_season                                     |\n",
      "|1      |hurricane - water - carolina - body - north           |Hurricane_Hermine                                             |\n",
      "|2      |p3546 - property - p3547 - melbourne - all-australians|Charlie_Spargo                                                |\n",
      "|3      |hurricane - water - carolina - body - north           |Hurricane_Otto                                                |\n",
      "|4      |11 - attack - 2001 - arabian - comic                  |Henryk_Siwiak_homicide                                        |\n",
      "|5      |football - player - australian - broadcaster - league |2017_Florida_Gators_football_team                             |\n",
      "|6      |pageant - miss - america - film - delegate            |The_Bandit_Run                                                |\n",
      "|7      |football - coach - conference - venue - season        |2018_Virginia_Tech_Hokies_football_team                       |\n",
      "|8      |pageant - miss - america - film - delegate            |Nia_Franklin                                                  |\n",
      "|9      |footballer - herzegovina - bosnia - under-21 - f.c.   |2019_UEFA_European_Under-21_Championship_qualification_Group_4|\n",
      "|10     |ice - hockey - medalist - winter - draft              |2019_NHL_Entry_Draft                                          |\n",
      "|11     |football - coach - conference - venue - season        |2018_Michigan_State_Spartans_football_team                    |\n",
      "|12     |football - coach - conference - venue - season        |2018_Kentucky_Wildcats_football_team                          |\n",
      "|13     |album - usage - miller - mac - singlechart            |Swimming_(Mac_Miller_album)                                   |\n",
      "|14     |football - coach - conference - venue - season        |2018_Appalachian_State_Mountaineers_football_team             |\n",
      "|15     |formula - driver - one - racing - championship        |2018_Singapore_Grand_Prix                                     |\n",
      "|16     |court - law - supreme - judge - lawyer                |Azar_v._Garza                                                 |\n",
      "|17     |football - coach - conference - venue - season        |2018_Kansas_Jayhawks_football_team                            |\n",
      "|18     |football - player - australian - broadcaster - league |2016_Florida_State_Seminoles_football_team                    |\n",
      "|19     |football - coach - conference - venue - season        |2018_Oregon_Ducks_football_team                               |\n",
      "+-------+------------------------------------------------------+--------------------------------------------------------------+\n",
      "\n",
      "max pagerank2 visualization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------+--------------------------------------------------------------+\n",
      "|cluster|LDA topics                                            |max isolated pagerank                                         |\n",
      "+-------+------------------------------------------------------+--------------------------------------------------------------+\n",
      "|0      |football - player - australian - broadcaster - league |2016_Detroit_Lions_season                                     |\n",
      "|1      |hurricane - water - carolina - body - north           |Marine_Corps_Air_Station_Cherry_Point                         |\n",
      "|2      |p3546 - property - p3547 - melbourne - all-australians|Charlie_Spargo                                                |\n",
      "|3      |hurricane - water - carolina - body - north           |Hurricane_Otto                                                |\n",
      "|4      |11 - attack - 2001 - arabian - comic                  |Henryk_Siwiak_homicide                                        |\n",
      "|5      |football - player - australian - broadcaster - league |SEC_Network                                                   |\n",
      "|6      |pageant - miss - america - film - delegate            |The_Bandit_Run                                                |\n",
      "|7      |football - coach - conference - venue - season        |2018_Virginia_Tech_Hokies_football_team                       |\n",
      "|8      |pageant - miss - america - film - delegate            |Nia_Franklin                                                  |\n",
      "|9      |footballer - herzegovina - bosnia - under-21 - f.c.   |2019_UEFA_European_Under-21_Championship_qualification_Group_4|\n",
      "|10     |ice - hockey - medalist - winter - draft              |2019_NHL_Entry_Draft                                          |\n",
      "|11     |football - coach - conference - venue - season        |Notre_Dame_Fighting_Irish_football_statistical_leaders        |\n",
      "|12     |football - coach - conference - venue - season        |2017_Tennessee_Volunteers_football_team                       |\n",
      "|13     |album - usage - miller - mac - singlechart            |Swimming_(Mac_Miller_album)                                   |\n",
      "|14     |football - coach - conference - venue - season        |2018_Appalachian_State_Mountaineers_football_team             |\n",
      "|15     |formula - driver - one - racing - championship        |2018_Singapore_Grand_Prix                                     |\n",
      "|16     |court - law - supreme - judge - lawyer                |Azar_v._Garza                                                 |\n",
      "|17     |football - coach - conference - venue - season        |2018_Kansas_Jayhawks_football_team                            |\n",
      "|18     |football - player - australian - broadcaster - league |Keion_Crossen                                                 |\n",
      "|19     |football - coach - conference - venue - season        |2018_Oregon_Ducks_football_team                               |\n",
      "+-------+------------------------------------------------------+--------------------------------------------------------------+\n",
      "\n",
      "max deg visualization\n",
      "+-------+------------------------------------------------------+-------------------------------------------------------------------+\n",
      "|cluster|LDA topics                                            |max degree                                                         |\n",
      "+-------+------------------------------------------------------+-------------------------------------------------------------------+\n",
      "|0      |football - player - australian - broadcaster - league |Sunday_NFL_Countdown                                               |\n",
      "|1      |hurricane - water - carolina - body - north           |Sandhills_(Carolina)                                               |\n",
      "|2      |p3546 - property - p3547 - melbourne - all-australians|Simon_Goodwin                                                      |\n",
      "|3      |hurricane - water - carolina - body - north           |Subtropical_cyclone                                                |\n",
      "|4      |11 - attack - 2001 - arabian - comic                  |List_of_unsuccessful_terrorist_plots_in_the_United_States_post-9/11|\n",
      "|5      |football - player - australian - broadcaster - league |ESPN2                                                              |\n",
      "|6      |pageant - miss - america - film - delegate            |Smokey_and_the_Bandit                                              |\n",
      "|7      |football - coach - conference - venue - season        |Graduate_assistant                                                 |\n",
      "|8      |pageant - miss - america - film - delegate            |Miss_Alabama                                                       |\n",
      "|9      |footballer - herzegovina - bosnia - under-21 - f.c.   |2019_UEFA_European_Under-21_Championship_qualification_Group_8     |\n",
      "|10     |ice - hockey - medalist - winter - draft              |Captain_(ice_hockey)                                               |\n",
      "|11     |football - coach - conference - venue - season        |Notre_Dame_Football_on_NBC                                         |\n",
      "|12     |football - coach - conference - venue - season        |University_of_Tennessee                                            |\n",
      "|13     |album - usage - miller - mac - singlechart            |Blue_Slide_Park                                                    |\n",
      "|14     |football - coach - conference - venue - season        |2007_Appalachian_State_Mountaineers_football_team                  |\n",
      "|15     |formula - driver - one - racing - championship        |Lewis_Hamilton                                                     |\n",
      "|16     |court - law - supreme - judge - lawyer                |United_States_Senate_Committee_on_the_Judiciary                    |\n",
      "|17     |football - coach - conference - venue - season        |Big_12_Conference_football                                         |\n",
      "|18     |football - player - australian - broadcaster - league |2014_Florida_State_Seminoles_football_team                         |\n",
      "|19     |football - coach - conference - venue - season        |Stanford_Cardinal_football                                         |\n",
      "+-------+------------------------------------------------------+-------------------------------------------------------------------+\n",
      "\n",
      "max deg2 visualization\n",
      "+-------+------------------------------------------------------+-------------------------------------------------------------------+\n",
      "|cluster|LDA topics                                            |max isolated degree                                                |\n",
      "+-------+------------------------------------------------------+-------------------------------------------------------------------+\n",
      "|0      |football - player - australian - broadcaster - league |2016_New_York_Jets_season                                          |\n",
      "|1      |hurricane - water - carolina - body - north           |Sandhills_(Carolina)                                               |\n",
      "|2      |p3546 - property - p3547 - melbourne - all-australians|Simon_Goodwin                                                      |\n",
      "|3      |hurricane - water - carolina - body - north           |Subtropical_cyclone                                                |\n",
      "|4      |11 - attack - 2001 - arabian - comic                  |List_of_unsuccessful_terrorist_plots_in_the_United_States_post-9/11|\n",
      "|5      |football - player - australian - broadcaster - league |ESPN_on_ABC                                                        |\n",
      "|6      |pageant - miss - america - film - delegate            |Smokey_and_the_Bandit                                              |\n",
      "|7      |football - coach - conference - venue - season        |Graduate_assistant                                                 |\n",
      "|8      |pageant - miss - america - film - delegate            |Miss_Alabama                                                       |\n",
      "|9      |footballer - herzegovina - bosnia - under-21 - f.c.   |2019_UEFA_European_Under-21_Championship_qualification_Group_8     |\n",
      "|10     |ice - hockey - medalist - winter - draft              |Captain_(ice_hockey)                                               |\n",
      "|11     |football - coach - conference - venue - season        |Michigan_State–Notre_Dame_football_rivalry                         |\n",
      "|12     |football - coach - conference - venue - season        |University_of_Tennessee                                            |\n",
      "|13     |album - usage - miller - mac - singlechart            |Blue_Slide_Park                                                    |\n",
      "|14     |football - coach - conference - venue - season        |Appalachian_State_Mountaineers                                     |\n",
      "|15     |formula - driver - one - racing - championship        |Lewis_Hamilton                                                     |\n",
      "|16     |court - law - supreme - judge - lawyer                |United_States_Senate_Committee_on_the_Judiciary                    |\n",
      "|17     |football - coach - conference - venue - season        |Big_12_Conference_football                                         |\n",
      "|18     |football - player - australian - broadcaster - league |Timmy_Jernigan                                                     |\n",
      "|19     |football - coach - conference - venue - season        |2018_Arizona_Wildcats_football_team                                |\n",
      "+-------+------------------------------------------------------+-------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ.setdefault('JAVA_HOME', '/usr/lib/jvm/java-1.8.0-openjdk-amd64')\n",
    "user = os.environ.get('USER')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "global lanuage\n",
    "language = 'en'\n",
    "\n",
    "from os import walk\n",
    "\n",
    "mypath = 'graphs/'+language+'/'\n",
    "max_num_communities = 20\n",
    "output_path = 'output/'+language+'/'\n",
    "#(_, _, filenames) = next(walk(mypath))\n",
    "#filenames = [\"peaks_graph_20190901_20190915.gexf\"]\n",
    "filenames = [\"peaks_graph_20180901_20180915.gexf\"]\n",
    "\n",
    "\n",
    "global language_mapper\n",
    "language_mapper = {\n",
    "    'en': 'Hidden_categories',\n",
    "    'fr': 'Catégorie_cachée'\n",
    "}\n",
    "\n",
    "global driver\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=('neo4j', 'tototo'))\n",
    "\n",
    "global spark\n",
    "spark = SparkSession.builder.appName('graph processing').config(\"spark.master\", \"local[*]\").config(\"spark.sql.warehouse.dir\", \"/home/\"+user+\"/warehouse\").getOrCreate()\n",
    "print(\"Access UI on : http://0.0.0.0:\" + spark.sparkContext.uiWebUrl.split(\":\")[-1])\n",
    "print(\"Spark warehouse set to :\", spark.conf.get('spark.sql.warehouse.dir'))\n",
    "\n",
    "for f in sorted(filenames):\n",
    "    path = mypath + f\n",
    "    (G_undir, G_dir, communities, part_cat_dict) = ld(path, max_num_communities)\n",
    "        \n",
    "    maxx = find_max_freq(count_all_frequencies(part_cat_dict))\n",
    "    \n",
    "    lda_df = topics_with_ml(communities, part_cat_dict)\n",
    "    \n",
    "    betweenness_central_nodes = betweenness_centrality_nodes(G_undir, communities)\n",
    "    \n",
    "    pr_result = max_pagerank(G_dir, communities)\n",
    "    pr_iso_result = max_pagerank_on_clusters(G_dir, communities)\n",
    "    \n",
    "    deg_result = max_degree(G_undir, communities)\n",
    "    deg_iso_result = max_degree_on_clusters(G_undir, communities)\n",
    "    \n",
    "    res = add_columns(lda_df,[(betweenness_central_nodes, 'betweenness central node'),\n",
    "                              (pr_result, 'max pagerank'),\n",
    "                              (pr_iso_result, 'max isolated pagerank'),\n",
    "                              (deg_result, 'max degree'),\n",
    "                              (deg_iso_result, 'max isolated degree'),\n",
    "                              (maxx, 'max category')])    \n",
    "    \n",
    "    print('betweenness central nodes visualization')\n",
    "    res.select('cluster', 'LDA topics', 'betweenness central node').show(truncate=False)\n",
    "    print('max pagerank visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max pagerank').show(truncate=False)\n",
    "    print('max pagerank2 visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max isolated pagerank').show(truncate=False)\n",
    "    print('max deg visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max degree').show(truncate=False)\n",
    "    print('max deg2 visualization')\n",
    "    res.select('cluster', 'LDA topics', 'max isolated degree').show(truncate=False)\n",
    "\n",
    "    G = add_attributes_from_df(G_undir, res)\n",
    "    \n",
    "    name = f[12:-5]\n",
    "    path = output_path+name+\"/\"\n",
    "    res.coalesce(1).write.csv(path, mode = 'overwrite')\n",
    "    nx.write_gexf(G, path+name+\".gexf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insider_neighbors_ratio(G, communities, ls):\n",
    "    res = {}\n",
    "    for cluster in ls:\n",
    "        node = ls[cluster]\n",
    "        neighbors = list(nx.classes.function.neighbors(G, node))\n",
    "        community_nodes = communities[cluster]\n",
    "        count = 0\n",
    "    \n",
    "        for n in neighbors:\n",
    "            if n in community_nodes:\n",
    "                count-=-1 #why not ;p\n",
    "    \n",
    "        ratio = \"{0:.2f}\".format(100 * count / len(neighbors))+'%'\n",
    "    \n",
    "        print(cluster, node, ratio)\n",
    "    \n",
    "        res.setdefault(cluster, (node, ratio))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Sunday_NFL_Countdown 72.41%\n",
      "1 Sandhills_(Carolina) 100.00%\n",
      "2 Simon_Goodwin 100.00%\n",
      "3 Subtropical_cyclone 94.12%\n",
      "4 List_of_unsuccessful_terrorist_plots_in_the_United_States_post-9/11 100.00%\n",
      "5 ESPN2 66.67%\n",
      "6 Smokey_and_the_Bandit 100.00%\n",
      "7 Graduate_assistant 53.85%\n",
      "8 Miss_Alabama 100.00%\n",
      "9 2019_UEFA_European_Under-21_Championship_qualification_Group_8 100.00%\n",
      "10 Captain_(ice_hockey) 100.00%\n",
      "11 Notre_Dame_Football_on_NBC 60.00%\n",
      "12 University_of_Tennessee 60.71%\n",
      "13 Blue_Slide_Park 100.00%\n",
      "14 2007_Appalachian_State_Mountaineers_football_team 81.25%\n",
      "15 Lewis_Hamilton 100.00%\n",
      "16 United_States_Senate_Committee_on_the_Judiciary 100.00%\n",
      "17 Big_12_Conference_football 88.89%\n",
      "18 2014_Florida_State_Seminoles_football_team 65.00%\n",
      "19 Stanford_Cardinal_football 42.31%\n"
     ]
    }
   ],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, deg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016_New_York_Jets_season 100.00%\n",
      "1 Sandhills_(Carolina) 100.00%\n",
      "2 Simon_Goodwin 100.00%\n",
      "3 Subtropical_cyclone 94.12%\n",
      "4 List_of_unsuccessful_terrorist_plots_in_the_United_States_post-9/11 100.00%\n",
      "5 ESPN_on_ABC 87.50%\n",
      "6 Smokey_and_the_Bandit 100.00%\n",
      "7 Graduate_assistant 53.85%\n",
      "8 Miss_Alabama 100.00%\n",
      "9 2019_UEFA_European_Under-21_Championship_qualification_Group_8 100.00%\n",
      "10 Captain_(ice_hockey) 100.00%\n",
      "11 Michigan_State–Notre_Dame_football_rivalry 100.00%\n",
      "12 University_of_Tennessee 60.71%\n",
      "13 Blue_Slide_Park 100.00%\n",
      "14 Appalachian_State_Mountaineers 100.00%\n",
      "15 Lewis_Hamilton 100.00%\n",
      "16 United_States_Senate_Committee_on_the_Judiciary 100.00%\n",
      "17 Big_12_Conference_football 88.89%\n",
      "18 Timmy_Jernigan 100.00%\n",
      "19 2018_Arizona_Wildcats_football_team 85.71%\n"
     ]
    }
   ],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, deg_iso_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016_Detroit_Lions_season 100.00%\n",
      "1 Hurricane_Hermine 54.55%\n",
      "2 Charlie_Spargo 100.00%\n",
      "3 Hurricane_Otto 95.00%\n",
      "4 Henryk_Siwiak_homicide 100.00%\n",
      "5 2017_Florida_Gators_football_team 76.47%\n",
      "6 The_Bandit_Run 100.00%\n",
      "7 2018_Virginia_Tech_Hokies_football_team 81.82%\n",
      "8 Nia_Franklin 100.00%\n",
      "9 2019_UEFA_European_Under-21_Championship_qualification_Group_4 100.00%\n",
      "10 2019_NHL_Entry_Draft 100.00%\n",
      "11 2018_Michigan_State_Spartans_football_team 86.67%\n",
      "12 2018_Kentucky_Wildcats_football_team 75.00%\n",
      "13 Swimming_(Mac_Miller_album) 100.00%\n",
      "14 2018_Appalachian_State_Mountaineers_football_team 90.00%\n",
      "15 2018_Singapore_Grand_Prix 100.00%\n",
      "16 Azar_v._Garza 100.00%\n",
      "17 2018_Kansas_Jayhawks_football_team 100.00%\n",
      "18 2016_Florida_State_Seminoles_football_team 61.11%\n",
      "19 2018_Oregon_Ducks_football_team 70.00%\n"
     ]
    }
   ],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, pr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016_Detroit_Lions_season 100.00%\n",
      "1 Marine_Corps_Air_Station_Cherry_Point 80.00%\n",
      "2 Charlie_Spargo 100.00%\n",
      "3 Hurricane_Otto 95.00%\n",
      "4 Henryk_Siwiak_homicide 100.00%\n",
      "5 SEC_Network 61.76%\n",
      "6 The_Bandit_Run 100.00%\n",
      "7 2018_Virginia_Tech_Hokies_football_team 81.82%\n",
      "8 Nia_Franklin 100.00%\n",
      "9 2019_UEFA_European_Under-21_Championship_qualification_Group_4 100.00%\n",
      "10 2019_NHL_Entry_Draft 100.00%\n",
      "11 Notre_Dame_Fighting_Irish_football_statistical_leaders 92.86%\n",
      "12 2017_Tennessee_Volunteers_football_team 50.00%\n",
      "13 Swimming_(Mac_Miller_album) 100.00%\n",
      "14 2018_Appalachian_State_Mountaineers_football_team 90.00%\n",
      "15 2018_Singapore_Grand_Prix 100.00%\n",
      "16 Azar_v._Garza 100.00%\n",
      "17 2018_Kansas_Jayhawks_football_team 100.00%\n",
      "18 Keion_Crossen 100.00%\n",
      "19 2018_Oregon_Ducks_football_team 70.00%\n"
     ]
    }
   ],
   "source": [
    "r = insider_neighbors_ratio(G_undir, communities, pr_iso_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('betweenness central nodes visualization')\\nres.select('cluster', 'LDA topics', 'betweenness central node').show(truncate=False)\\nprint('max pagerank visualization')\\nres.select('cluster', 'LDA topics', 'max pagerank').show(truncate=False)\\nprint('max pagerank2 visualization')\\nres.select('cluster', 'LDA topics', 'max isolated pagerank').show(truncate=False)\\nprint('max deg visualization')\\nres.select('cluster', 'LDA topics', 'max degree').show(truncate=False)\\nprint('max deg2 visualization')\\nres.select('cluster', 'LDA topics', 'max isolated degree').show(truncate=False)\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print('betweenness central nodes visualization')\n",
    "res.select('cluster', 'LDA topics', 'betweenness central node').show(truncate=False)\n",
    "print('max pagerank visualization')\n",
    "res.select('cluster', 'LDA topics', 'max pagerank').show(truncate=False)\n",
    "print('max pagerank2 visualization')\n",
    "res.select('cluster', 'LDA topics', 'max isolated pagerank').show(truncate=False)\n",
    "print('max deg visualization')\n",
    "res.select('cluster', 'LDA topics', 'max degree').show(truncate=False)\n",
    "print('max deg2 visualization')\n",
    "res.select('cluster', 'LDA topics', 'max isolated degree').show(truncate=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import argparse\\n\\ndef parseArguments():\\n    # Create argument parser\\n    parser = argparse.ArgumentParser()\\n\\n    # Optional arguments\\n    parser.add_argument(\"-jdk8\", \"--jdk8Path\", help=\"path to jdk8. Default : /usr/lib/jvm/java-1.8.0-openjdk-amd64\", type=str, default=\\'/usr/lib/jvm/java-1.8.0-openjdk-amd64\\')\\n    parser.add_argument(\"-n4jadr\", \"--neo4jAddress\", help=\"neo4j database address. Default : bolt://localhost:7687\", type=str, default=\\'bolt://localhost:7687\\')\\n    parser.add_argument(\"-n4jusr\", \"--neo4jUsername\", help=\"neo4j database username. Default : neo4j\", type=str, default=\\'neo4j\\')\\n    parser.add_argument(\"-n4jpwd\", \"--neo4jPassword\", help=\"neo4j database password. Default : neo4j\", type=str, default=\\'neo4j\\')\\n    parser.add_argument(\"-ip\", \"--inputPath\", help=\"path of the directory containing the graphs. Default : graphs/\", type=str, default=\\'graphs/\\')\\n    parser.add_argument(\"-n\", \"--nOfClusters\", help=\"max number of clusters to extract. Default : 20\", type=int, default=20)\\n    parser.add_argument(\"-op\", \"--outputPath\", help=\"path of the output directory. Default : output/\", type=str, default=\\'output/\\')\\n\\n    # Parse arguments\\n    args = parser.parse_args()\\n\\n    return args\\n    \\nmain(parseArguments())\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import argparse\n",
    "\n",
    "def parseArguments():\n",
    "    # Create argument parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Optional arguments\n",
    "    parser.add_argument(\"-jdk8\", \"--jdk8Path\", help=\"path to jdk8. Default : /usr/lib/jvm/java-1.8.0-openjdk-amd64\", type=str, default='/usr/lib/jvm/java-1.8.0-openjdk-amd64')\n",
    "    parser.add_argument(\"-n4jadr\", \"--neo4jAddress\", help=\"neo4j database address. Default : bolt://localhost:7687\", type=str, default='bolt://localhost:7687')\n",
    "    parser.add_argument(\"-n4jusr\", \"--neo4jUsername\", help=\"neo4j database username. Default : neo4j\", type=str, default='neo4j')\n",
    "    parser.add_argument(\"-n4jpwd\", \"--neo4jPassword\", help=\"neo4j database password. Default : neo4j\", type=str, default='neo4j')\n",
    "    parser.add_argument(\"-ip\", \"--inputPath\", help=\"path of the directory containing the graphs. Default : graphs/\", type=str, default='graphs/')\n",
    "    parser.add_argument(\"-n\", \"--nOfClusters\", help=\"max number of clusters to extract. Default : 20\", type=int, default=20)\n",
    "    parser.add_argument(\"-op\", \"--outputPath\", help=\"path of the output directory. Default : output/\", type=str, default='output/')\n",
    "\n",
    "    # Parse arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "    \n",
    "main(parseArguments())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"I go to the moon\")\n",
    "for e in doc:\n",
    "    print (type(e.lemma_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more centrality attributes: pagerank, degrees, and try to find others\n",
    "\n",
    "make code a sort of an executable tool with arguments etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take node with highest degree in each cluster and find its neighbors and seee how many are in the same cluster\n",
    "==> the second variant (using just insiders to compute deg and pagerank) has better ratios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
