{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import modularity_max as mm\n",
    "import community\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import wikipediaapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"peaks_graph_20190901_20190915.gexf\"\n",
    "g = nx.read_gexf(path, node_type=None, relabel=True).to_undirected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30, 20)) # set size\n",
    "nx.draw(g, with_labels=True)\n",
    "plt.show()\n",
    "print('number of nodes : ' + str(len(g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree computation + mean + std + threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_with_degrees = g.degree\n",
    "\n",
    "mean_deg = statistics.mean(l[1] for l in nodes_with_degrees)\n",
    "\n",
    "std_deg = statistics.stdev(l[1] for l in nodes_with_degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering highly connected nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = mean_deg + std_deg*std_deg/2 \n",
    "\n",
    "nodes_to_remove = list(filter(lambda d : d[1] > threshold, nodes_with_degrees))\n",
    "\n",
    "n,d = zip(*nodes_to_remove)\n",
    "\n",
    "g.remove_nodes_from(n)\n",
    "print('remaining nodes : ' + str(len(g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree of nodes and filtering isolated nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_with_degrees = g.degree\n",
    "\n",
    "nodes_to_remove = list(filter(lambda d : d[1] == 0, nodes_with_degrees))\n",
    "\n",
    "n,d = zip(*nodes_to_remove)\n",
    "\n",
    "g.remove_nodes_from(n)\n",
    "\n",
    "print('remaining nodes : ' + str(len(g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only largest connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcc = max(nx.connected_component_subgraphs(g), key=len)\n",
    "\n",
    "print('remaining nodes : ' + str(len(gcc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(100, 70)) # set size\n",
    "nx.draw(gcc, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_partition = community.best_partition(gcc)\n",
    "print(len(best_partition))\n",
    "\n",
    "best_partition_dict = {}\n",
    "\n",
    "for key, value in sorted(best_partition.items()):\n",
    "    best_partition_dict.setdefault(value, []).append(key)\n",
    "\n",
    "print(len(best_partition_dict))\n",
    "print(best_partition_dict[0])\n",
    "print(sorted(best_partition_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup wikipedia-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categoriy of each partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get list of categories of a page\n",
    "def get_categories(page):\n",
    "    categories = list(page.categories.keys())\n",
    "    return categories\n",
    "    \n",
    "#filter out hidden categories from a list of categories\n",
    "def filter_categories_helper(ls):\n",
    "    res = []\n",
    "    for category in ls:\n",
    "        p = wiki_wiki.page(category)\n",
    "        cs = get_categories(p)\n",
    "        if not('Category:Hidden categories' in cs):\n",
    "            res += [category]\n",
    "    return res\n",
    "\n",
    "#map each element to frequency in a list    \n",
    "def count_frequency(my_list): \n",
    "      \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    for items in my_list: \n",
    "        freq[items] = my_list.count(items)\n",
    "    return freq\n",
    "\n",
    "#iterate over pages dict partition\n",
    "def part_category_fetch(key, dic):\n",
    "    cat = []\n",
    "    for title in dic[key]:\n",
    "#        print('\\t' + str(title))\n",
    "        page = wiki_wiki.page(title)\n",
    "        cat += get_categories(page)\n",
    "    print('done fetching')\n",
    "    return cat\n",
    "\n",
    "#\n",
    "def filter_categories(cmf):\n",
    "    values = list(cmf.values())\n",
    "    m = statistics.mean(values)\n",
    "    s = statistics.stdev(values)\n",
    "    \n",
    "    cat_map_highfreq = {key:val for key, val in cmf.items() if val >= m}\n",
    "    \n",
    "    tmp = cmf\n",
    "    \n",
    "    tmp.pop((e for e in cat_map_highfreq.keys()), None)\n",
    "    \n",
    "    cat_highfreq_list = list(cat_map_highfreq.keys())   \n",
    "    filtered_cat = filter_categories_helper(cat_highfreq_list)\n",
    "    \n",
    "    tmp = {**tmp, **{k:cat_map_highfreq[k] for k in filtered_cat}}\n",
    "    \n",
    "    values = list(tmp.values())\n",
    "    m = statistics.mean(values)\n",
    "    s = statistics.stdev(values)\n",
    "    \n",
    "    cat_map_highfreq = {key:val for key, val in tmp.items() if val >= m}\n",
    "    \n",
    "    cat_highfreq_list = list(cat_map_highfreq.keys())   \n",
    "    filtered_cat = filter_categories_helper(cat_highfreq_list)\n",
    "    \n",
    "    c = {k:cat_map_highfreq[k] for k in filtered_cat}\n",
    "    \n",
    "    \n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_categories(bpd):\n",
    "    part_cat = {}\n",
    "    \n",
    "    for part in reversed(sorted(bpd)):\n",
    "        print(part)\n",
    "        cat = part_category_fetch(part, bpd)\n",
    "        cat_map_freq = count_frequency(cat)\n",
    "        c = filter_categories(cat_map_freq)\n",
    "        print('**********categories are :')\n",
    "        for e in c.keys():\n",
    "            print(str(e) + ' : ' +str(c[e]))\n",
    "        c2 = {v:k for k,v in c.items()}\n",
    "        final_cat_freq = max(c2)\n",
    "        final_cat = c2[final_cat_freq]\n",
    "        print('**********final category')\n",
    "        print(str(final_cat)+ ' : '+ str(final_cat_freq))\n",
    "        part_cat.setdefault(part, []).append(final_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fetch_categories(best_partition_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = part_category_fetch(29, best_partition_dict)\n",
    "cmf = count_frequency(cat)\n",
    "\n",
    "tmp = cmf\n",
    "\n",
    "values = list(cmf.values())\n",
    "m = statistics.mean(values)\n",
    "s = statistics.stdev(values)\n",
    "print(m,s)\n",
    "cat_map_highfreq = {key:val for key, val in cmf.items() if val >= m}\n",
    "print(len(cat_map_highfreq))\n",
    "print(len(tmp))\n",
    "for e in cat_map_highfreq.keys():\n",
    "    tmp.pop(e, None)\n",
    "print(len(tmp))\n",
    "cat_highfreq_list = list(cat_map_highfreq.keys())   \n",
    "filtered_cat = filter_categories_helper(cat_highfreq_list)\n",
    "    \n",
    "tmp.update([(k, cat_map_highfreq[k]) for k in filtered_cat])\n",
    "    \n",
    "values = list(tmp.values())\n",
    "m = statistics.mean(values)\n",
    "s = statistics.stdev(values)\n",
    "print(m,s)\n",
    "cat_map_highfreq = {key:val for key, val in tmp.items() if val >= m}\n",
    "for k, v in cat_map_highfreq.items():\n",
    "    print(v,k)\n",
    "cat_highfreq_list = list(cat_map_highfreq.keys())   \n",
    "print(len(cat_highfreq_list))\n",
    "filtered_cat = filter_categories_helper(cat_highfreq_list)\n",
    "    \n",
    "c = {k:cat_map_highfreq[k] for k in filtered_cat}\n",
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
